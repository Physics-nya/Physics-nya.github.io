<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Notes for Mathematical Methods for Physicists</title>
    <link href="/2024/03/26/Mathematical%20Methods%20for%20Physicist/"/>
    <url>/2024/03/26/Mathematical%20Methods%20for%20Physicist/</url>
    
    <content type="html"><![CDATA[\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere\PassOptionsToPackage{hyphens}{url}%\documentclass[]{article}\usepackage{lmodern}\usepackage{amssymb,amsmath}\usepackage{ifxetex,ifluatex}\usepackage{fixltx2e} % provides \textsubscript\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex  \usepackage[T1]{fontenc}  \usepackage[utf8]{inputenc}  \usepackage{textcomp} % provides euro and other symbols\else % if luatex or xelatex  \usepackage{unicode-math}  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}\fi% use upquote if available, for straight quotes in verbatim environments\IfFileExists{upquote.sty}{\usepackage{upquote}}{}% use microtype if available\IfFileExists{microtype.sty}{%\usepackage[]{microtype}\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts}{}\IfFileExists{parskip.sty}{%\usepackage{parskip}}{% else\setlength{\parindent}{0pt}\setlength{\parskip}{6pt plus 2pt minus 1pt}}\usepackage{hyperref}\hypersetup{            pdfborder={0 0 0},            breaklinks=true}\urlstyle{same}  % don't use monospace font for urls\usepackage{longtable,booktabs}% Fix footnotes in tables (requires footnote package)\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}\setlength{\emergencystretch}{3em}  % prevent overfull lines\providecommand{\tightlist}{%  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\setcounter{secnumdepth}{0}% Redefines (sub)paragraphs to behave more like sections\ifx\paragraph\undefined\else\let\oldparagraph\paragraph\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}\fi\ifx\subparagraph\undefined\else\let\oldsubparagraph\subparagraph\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}\fi% set default figure placement to htbp\makeatletter\def\fps@figure{htbp}\makeatother\date{}\begin{document}\hypertarget{notes-on-mathematical-methods-for-physicists}{%\section{Notes on Mathematical Methods forPhysicists}\label{notes-on-mathematical-methods-for-physicists}}\hypertarget{chapter1-mathematical-preliminaries}{%\subsection{Chapter1 MathematicalPreliminaries}\label{chapter1-mathematical-preliminaries}}\hypertarget{uxa7uxauxa711uxa-infinite-series}{%\subsubsection{\texorpdfstring{\(\S1.1\) InfiniteSeries}{\textbackslash{}S1.1 Infinite Series}}\label{uxa7uxauxa711uxa-infinite-series}}\hypertarget{ux25fbuxa-comparison-test}{%\paragraph{\texorpdfstring{\(\square\) ComparisonTest}{\textbackslash{}square Comparison Test}}\label{ux25fbuxa-comparison-test}}Consider a convergent series \{\(a_n\)\} , we can use \{\(a_n\)\} tostudy the convergence of series \{\(u_n\)\} :\(0\leq u_n \leq a_n \Rightarrow \) \{\(u_n\)\} is convergent.Similarly , consider a divergent series \{\(a_n\)\} , we can use\{\(a_n\)\} to study the convergence of series \{\(u_n\)\} :\(u_n \geq a_n \geq 0 \Rightarrow\) \{\(u_n\)\} is divergent.\hypertarget{ux25fbuxa-cauchy-root-test}{%\paragraph{\texorpdfstring{\(\square\) Cauchy RootTest}{\textbackslash{}square Cauchy Root Test}}\label{ux25fbuxa-cauchy-root-test}}\((a_n)^{1/n}\leq r < 1 \Rightarrow\) \{\(a_n\)\} is convergent.\((a_n)^{1/n} \geq 1 \Rightarrow\) \{\(a_n\)\} is divergent.\hypertarget{ux25fbuxa-dalembert-or-cauchy-ratio-test}{%\paragraph{\texorpdfstring{\(\square\) d'Alembert (or Cauchy) RatioTest}{\textbackslash{}square d'Alembert (or Cauchy) Ratio Test}}\label{ux25fbuxa-dalembert-or-cauchy-ratio-test}}\(\frac{a_{n+1}}{a_n}~\leq r<1 \Rightarrow\) \{\(a_n\)\} is convergent.\(\frac{a_{n+1}}{a_n}~\geq 1\Rightarrow\) \{\(a_n\)\} is divergent.\(\begin{equation}\underset{n\to\infty}{lim}~(\frac{a_{n+1}}{a_n})\left\{\begin{array}{lr}<1,\quad congvergent &\\=1,\quad divergent &\\>1,\quad indeterminate &\end{array}\right.\end{equation}\)At some crucial point , the test may fail. For example ,\(a_n=\frac{1}{n}\) (harmonic series) :\[\frac{a_{n+1}}{a_n}~=~\frac{n}{n+1}<1\]but we cannot find r (\textless{} 1) independent of n.Since \(\underset{n\to\infty}{lim}\frac{a_{n+1}}{a_n}~=1\) , the testfails.\hypertarget{ux25fbuxa-cauchy-or-maclaurin-integral-test}{%\paragraph{\texorpdfstring{\(\square\) Cauchy (or Maclaurin) IntegralTest}{\textbackslash{}square Cauchy (or Maclaurin) Integral Test}}\label{ux25fbuxa-cauchy-or-maclaurin-integral-test}}Consider \(f(x)\) a continuous , monotonic decreasing function , inwhich \(f(n)=a_n\).\[\int_{1}^{\infty}f(x)dx\leq \sum_{n=1}^{\infty}~a_n \leq\int_{1}^{\infty}f(x)dx+a_1\]We have an equation , it writes ,\[\sum_{n=N_1+1}^{N_2}f(n)=\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}(x-[x])f'(x)dx\]proof :\begin{flalign}RHS=&\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}(x-[x])f'(x)dx\\=&\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}xf'(x)dx-\int_{N_1}^{N_2}[x]f(x)dx\\=&\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}xd(f(x))-\sum_{n=N_1}^{N_2-1}n\int_{n}^{n+1}f'(x)dx\\=&\int_{N_1}^{N_2}f(x)dx+N_2f(N_2)-N_1f(N_1)-\int_{N_1}^{N_2}f(x)dx-\sum_{N_1}^{N_2-1}n(f(n+1)-f(n))\\=&N_2f(N_2)-N_1f(N_1)-\sum_{N_1}^{N_2-1}n(f(n+1)-f(n))\\=&N_2f(N_2)-N_1f(N_1)+\sum_{n=N_1+1}^{N_2}f(n)+N_1f(N_1)-N_2f(N_2)\\=&\sum_{n=N_1+1}^{N_2}f(n)\end{flalign}Then \(RHS=LHS\).\(Q.E.D\quad\blacksquare\)Alternative of the equation :\[\sum_{n=N_1+1}^{N_2}f(n)=\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}(x-[x]-\frac{1}{2})dx+\frac{1}{2}~(f(N_2)-f(N_1))\]In this kind of equation , the second part in the right hand side is afunction that oscillates about zero.\hypertarget{ux25fbuxa-more-sensitive-tests}{%\paragraph{\texorpdfstring{\(\square\) More SensitiveTests}{\textbackslash{}square More Sensitive Tests}}\label{ux25fbuxa-more-sensitive-tests}}\#\#\#\#\# 1. Kummer TheoremIf\(\underset{n\to\infty}{lim}(a_n\frac{u_N}{u_{n+1}}-a_{n+1})\geq C>0\) ,where \(C\) is a constant , we have \{\(u_n\)\} is convergent if\(\sum_{n}a_n^{-1}\) is convergent. \textbf{And if \(\sum_{n}a_n^{-1}\)is divergent , the more weak it diverges , the more powerful the theoremwill be.}If \(\underset{n\to\infty}{lim}(a_n\frac{u_N}{u_{n+1}}-a_{n+1})\leq 0\), we have \{\(u_n\)\} is divergent if \(\sum_{n}a_n^{-1}\) is divergent.proof :\begin{flalign}u_{N+1}&\leq(a_Nu_N-a_{N+1}u_{N+1})/C\\u_{N}&\leq(a_{N-1}u_{N-1}-a_{N}u_{N})/C\\...&\leq...\quad...\\\Rightarrow\sum_{i=N+1}^{n}u_i&=(a_Nu_N-a_nu_n)/C<a_Nu_N/C\\\Rightarrow\quad&Convergent\end{flalign}\hypertarget{2gaussstestuxa}{%\subparagraph{\texorpdfstring{\(2.\quad Gauss's\quad Test\)}{2.\textbackslash{}quad Gauss's\textbackslash{}quad Test}}\label{2gaussstestuxa}}For large n , \(\frac{u_n}{u_{n+1}}=1+\frac{h}{n}+\frac{B(n)}{n^2}\) ,we can know that\begin{equation}\left\{\begin{array}{lr}h>1\quad\Rightarrow\quad convergent\\h\leq1\quad\Rightarrow\quad divergent\end{array}\right.\end{equation}\hypertarget{ux25fbalternatingseriesuxa}{%\paragraph{\texorpdfstring{\(\square\quad Alternating\quad Series\)}{\textbackslash{}square\textbackslash{}quad Alternating\textbackslash{}quad Series}}\label{ux25fbalternatingseriesuxa}}For series of the form \(\sum_{n=1}^{\infty}(-1)^{n+1}a_n\) , \(a_n>0\), we have Leibniz Criterion :\textbf{If \(a_n\) monotonically decreases , and\(lim_{n\to\infty}a_n=0\) , then \{\(a_n\)\} converges.}proof :\begin{flalign}&R_{2n}=(a_{2n+1}-a_{2n+2})+(a_{2n+3}-a_{2n+4})+···>0\\&R_{2n}=a_{2n+1}-(a_{2n+2}-a_{2n+3})-(a_{2n+4}-a_{2n+5})-···<a_{2n+1}\\&\Rightarrow\quad 0<R_{2n}<a_{2n+1}\end{flalign}so when \(n\uparrow,R_{2n}\uparrow\).\(Q.E.D\quad \blacksquare\)\hypertarget{ux25fbabsoluteconditionalconvergenceuxa}{%\paragraph{\texorpdfstring{\(\square\quad Absolute\quad \&\quad Conditional\quad Convergence\)}{\textbackslash{}square\textbackslash{}quad Absolute\textbackslash{}quad \textbackslash{}\&\textbackslash{}quad Conditional\textbackslash{}quad Convergence}}\label{ux25fbabsoluteconditionalconvergenceuxa}}Absolute convergence : the absolute value of its terms form a convergentseries.Conditional convergence : not the situation above.\hypertarget{ux25fboperationonseriesuxa}{%\paragraph{\texorpdfstring{\(\square\quad Operation\quad on\quad Series\)}{\textbackslash{}square\textbackslash{}quad Operation\textbackslash{}quad on\textbackslash{}quad Series}}\label{ux25fboperationonseriesuxa}}\(\bullet\) If an infinite series is absolutely convergent , the seriessum is independent of the order in which the terms are added.\(\bullet\) An absolutely convergent series may be added termwise to ,or subtracted termwise from , or multiplied termwise with anotherabsolutely convergent series , and the resulting series will also beabsolutely convergent.\(\bullet\) The series (as a whole) may be multiplied with anotherabsolutely convergent series. The limit of the product will be theproduct of the individual series limits. The product series , a doubleseries , will also convergent absolutely.\hypertarget{ux25fbimprovementofconvergenceuxa}{%\paragraph{\texorpdfstring{\(\square\quad Improvement\quad of\quad Convergence\)}{\textbackslash{}square\textbackslash{}quad Improvement\textbackslash{}quad of\textbackslash{}quad Convergence}}\label{ux25fbimprovementofconvergenceuxa}}The rate of convergence : to form a linear combination of our slowlyconverging series and one or more series whose sum is known.For the known series , the following collection is particularly useful :\[\alpha_1=\sum_{n=1}^{\infty}\frac{1}{n(n+1)}=1\\\alpha_2=\sum_{n=1}^{\infty}\frac{1}{n(n+1)(n+2)}=\frac{1}{4}\\\alpha_3=\sum_{n=1}^{\infty}\frac{1}{n(n+1)(n+2)(n+3)}=\frac{1}{18}\\...\\\alpha_p=\sum_{n=1}^{\infty}\frac{1}{n(n+1)···(n+p)}=\frac{1}{p·p!}\]The series we want to sum and one or more known series (multiplied bycoefficient) are combined term by term. The coefficients in the linearcombination are chosen to cancel the most slowly converging terms.\hypertarget{ux25fbrearrangementofdoubleseriesuxa}{%\paragraph{\texorpdfstring{\(\square\quad Rearrangement\quad of\quad Double\quad Series\)}{\textbackslash{}square\textbackslash{}quad Rearrangement\textbackslash{}quad of\textbackslash{}quad Double\textbackslash{}quad Series}}\label{ux25fbrearrangementofdoubleseriesuxa}}For \(S=\sum_{m=0}^{\infty}\sum_{n=0}^{\infty}a_{n,m}\) ,\begin{equation}rearrangement\quad of\quad S=\left\{\begin{array}{lr}\sum_{p=0}^{\infty}\sum_{q=0}^{p}a_{p-q,q}\\\sum_{q=0}^{\infty}\sum_{p=q}^{\infty}a_{p-q,q}\\\sum_{r=0}^{\infty}\sum_{s=0}^{[r/2]}a_{s,r-2s}\end{array}\right.\end{equation}\hypertarget{uxa7uxauxa712seriesoffunctionsuxa}{%\subsubsection{\texorpdfstring{\(\S1.2\quad Series\quad of\quad Functions\)}{\textbackslash{}S1.2\textbackslash{}quad Series\textbackslash{}quad of\textbackslash{}quad Functions}}\label{uxa7uxauxa712seriesoffunctionsuxa}}Let's extend our concept of infinite series to include series offunctions :\[s_n(x)=&u_1(x)+u_2(x)+···+u_n(x)\\S(x)=&\sum_{n=1}^{\infty}u_n(x)=lim_{n\to\infty}s_n(x)\]\hypertarget{ux25fbuniformconvergenceuxa}{%\paragraph{\texorpdfstring{\(\square\quad Uniform\quad Convergence\)}{\textbackslash{}square\textbackslash{}quad Uniform\textbackslash{}quad Convergence}}\label{ux25fbuniformconvergenceuxa}}If for any small \(\epsilon>1\) , there exists a number \(N\) ,independent of \(x\) in the interval {[}\(a,b\){]} (that is , \(a<x<b\))such that ,\[|S(x)-s_n(x)|<\epsilon , for\quad all\quad n\geq N\]Then the series is said to be \textbf{uniformly convergent}.\hypertarget{ux25fbweierstrassmmajoranttestuxa}{%\paragraph{\texorpdfstring{\(\square\quad Weierstrass\quad M(Majorant)\quad Test\)}{\textbackslash{}square\textbackslash{}quad Weierstrass\textbackslash{}quad M(Majorant)\textbackslash{}quad Test}}\label{ux25fbweierstrassmmajoranttestuxa}}If we can construct a series of numbers \(\sum_{i=1}^{\infty}M_i\) , inwhich \(M_i\geq|u_i(x)|\) for all \(x\) in the interval {[}\(a,b\){]} ,and \(\sum_{i=1}^{\infty}M_i\) is convergent , then our series\(u_i(x)\) will be \textbf{uniformly convergent} in {[}\(a,b\){]}.proof :\[&\sum_{i=n+1}^{\infty}M_i<\epsilon,\quad\sum_{i=n+1}^{\infty}M_i>\sum_{i=n+1}^{\infty}u_i(x)\\&\Rightarrow\sum_{i=n+1}^{\infty}u_i(x)<\epsilon\\&\Rightarrow|S(x)-s_n(x)|=|\sum_{i=n+1}^{\infty}u_i(x)|<\epsilon&\]\textbf{Uniform convergence has nothing with absolute convergence.} ButM test can only establish for absolutely convergent series.\hypertarget{ux25fbabelstestuxa}{%\paragraph{\texorpdfstring{\(\square\quad Abel's\quad Test\)}{\textbackslash{}square\textbackslash{}quad Abel's\textbackslash{}quad Test}}\label{ux25fbabelstestuxa}}A somewhat more delicate test for uniform convergence has been given byAbel. If \(u_n(x)\) can be written in the uniform \(a_nf_n(x)\) , and\begin{enumerate}\def\labelenumi{\arabic{enumi}.}\item  The \(a_n\) form a convergent series , \(\sum_{n}a_n=A\).\item  For all \(x\) in {[}\(a,b\){]} the functions \(f_n(x)\) are  monotonically decreasing in \(n\) , that is ,  \(f_{n+1}(x)\leq f_{n}(x)\).\item  For all \(x\) in {[}\(a,b\){]} , all the \(f_n(x)\) are bounded in the  range \(0\leq f_n(x)\leq M\) , where \(M\) is independent of \(x\). \end{enumerate}Then \(\sum_{n}u_n(x)\) converges uniformly in {[}\(a,b\){]}. Thismethod is especially useful in analyzing the convergence of powerseries.\hypertarget{ux25fbpropertiesofuniformlyconvergentseriesuxa}{%\paragraph{\texorpdfstring{\(\square\quad Properties\,\,of\,\,Uniformly\,\,Convergent\,\,Series\)}{\textbackslash{}square\textbackslash{}quad Properties\textbackslash{},\textbackslash{},of\textbackslash{},\textbackslash{},Uniformly\textbackslash{},\textbackslash{},Convergent\textbackslash{},\textbackslash{},Series}}\label{ux25fbpropertiesofuniformlyconvergentseriesuxa}}If a series \(\sum_nu_n(x)\) is uniformly convergent in {[}\(a,b\){]}and the individual terms \(u_n(x)\) are continuous ,\begin{enumerate}\def\labelenumi{\arabic{enumi}.}\item  The series sum \(S(x)=\sum_{n=1}^{\infty}u_n(x)\) is also continuous ,\item  \(\int_{a}^{b}S(x)dx=\sum_{n=1}^{\infty}\int_{a}^{b} u_n(x)\) ,\item  if the following additional conditions are also satisfied , then  \(\sum_{n=1}^{\infty}\frac{du_n(x)}{dx}\) is uniformly convergent in  {[}\(a,b\){]} : \(\frac{du_n(x)}{dx}\) is continuous in {[}\(a,b\){]}.\end{enumerate}The first and second conditions are always right in physics , but thethird is not because it is more restrictive.\hypertarget{ux25fbtaylorsexpansionuxa}{%\paragraph{\texorpdfstring{\(\square\quad Taylor's\quad Expansion\)}{\textbackslash{}square\textbackslash{}quad Taylor's\textbackslash{}quad Expansion}}\label{ux25fbtaylorsexpansionuxa}}We assume that our function \(f(x)\) has a continuous n-th derivative inthe interval {[}\(a,b\){]}.First , let's intergrate this n-th derivative n times :\[\int_{a}^{x}f^{(n)}(x_1)dx_1=f^{(n-1)}(x)-f^{(n-1)}(a)\\\int_{a}^{x}(\int_{a}^{x_2}f^{(n)}(x_1)dx_1)dx_2=f^{(n-2)}(x)-f^{(n-2)}(a)-(x-a)f^{(n-1)}(a)\\\int_{a}^{x}(\int_{a}^{x_3}(\int_{a}^{x_2}f^{(n)}(x_1)dx_1)dx_2)dx_3=\\f^{(n-3)}(x)-f^{(n-3)}(a)-(x-a)f^{(n-2)}(a)-\frac{(x-a)^2}{2!}f^{(n-1)}(a)\\···\]Finally ， after integrating for the n-th time ,\[\int_{a}^{x}dx_{n}\int_{a}^{x_n}dx_{n-1}···\int_{a}^{x_{2}}dx_1·f^{(n)}(x)=\\f(x)-f(a)-(x-a)f'(a)-\frac{(x-a)^2}{2!}f''(a)-···-\frac{(x-a)^{n-1}}{(n-1)!}f^{(n-1)}(a)\\\Rightarrow f(x)=f(a)+(x-a)f'(a)+\frac{(x-a)^2}{2!}f''(a)+···+\frac{(x-a)^{n-1}}{(n-1)!}f^{(n-1)}(a)+R_n\]where the remainder , \(R_n\) , is given by the n-fold integral ,\[R_n=\int_{a}^{x}dx_{n}\int_{a}^{x_n}dx_{n-1}···\int_{a}^{x_{2}}dx_1·f^{(n)}(x)\]We may convert \(R_n\) into a perhaps more pratical form by using themean value theorem of integral calculus ,\[\int_{a}^{x}g(x)dx=(x-a)g(\xi)\\\begin{flalign}\Rightarrow R_n&=\int_{a}^{x}dx_{n}\int_{a}^{x_n}dx_{n-1}···\int_{a}^{x_{2}}dx_1·f^{(n)}(x)\\&=\frac{(x-a)^n}{n!}f^{(n)}(\xi)\\\end{flalign}\]Or applying Cauchy's mean value theorem of integral calculus ,\[R_n=\frac{(x-\xi)^{n-1}(x-a)}{(n-1)!}f^{(n)}(\xi)\]When you adjust n properly , \(R_n\to0\). Then we have \textbf{TaylorExpansion} , which writes\[f(x)=\sum_{n=0}^{\infty}\frac{(x-a)^n}{n!}f^{(n)}(a)\]\hypertarget{ux25fbpowerseriesuxa}{%\paragraph{\texorpdfstring{\(\square\quad Power\quad Series\)}{\textbackslash{}square\textbackslash{}quad Power\textbackslash{}quad Series}}\label{ux25fbpowerseriesuxa}}When \(a=0\) , we have Maclaurin series ,\[f(x)=f(0)+xf'(x)+\frac{x^2}{2!}f''(0)+···=\sum_{n=0}^{\infty}\frac{x^n}{n!}f^{(n)}(0)\]\hypertarget{ux25fbpropertiesofpowerseriesuxa}{%\paragraph{\texorpdfstring{\(\square\quad Properties\quad of\quad Power\quad Series\)}{\textbackslash{}square\textbackslash{}quad Properties\textbackslash{}quad of\textbackslash{}quad Power\textbackslash{}quad Series}}\label{ux25fbpropertiesofpowerseriesuxa}}\(f(x)=\sum_{n=0}^{\infty}a_nx^n\) , in which \(a_n\) is independent of\(x\). If \(lim_{n\to\infty}|\frac{a_{n+1}}{a_n}|=R^{-1}\) , then \(R\)is the radius of convergence , and the series converges for\(x\in(-R,R)\).But the ratio / root test fails at endpoints , \(x=\pm R\) needs specialattention. In M test , the series is uniformly and absolutely convergentin (\(-R,R\)).\hypertarget{ux25fbuniquenesstheoremuxa}{%\paragraph{\texorpdfstring{\(\square\quad Uniqueness\quad Theorem\)}{\textbackslash{}square\textbackslash{}quad Uniqueness\textbackslash{}quad Theorem}}\label{ux25fbuniquenesstheoremuxa}}\textbf{The power-series representation is unique.} Assume that\begin{flalign}f(x)&=\sum_{n=0}^{\infty}a_nx^n,\quad -R_a<x<R_a\\&=\sum_{n=0}^{\infty}b_nx^n,\quad -R_b<x<R_b\end{flalign}What we need to prove is that \(a_n=b_n\) , for all \(n\).\[\sum_{n=0}^{\infty}a_nx^n=\sum_{n=0}^{\infty}b_nx^n,\quad -R<x<R\\in\quad which\quad R\leq R_a\,,\,R_b\]When \(x=0\) , we have \(a_0=b_0\). Then differentiate the series ,\[\sum_{n=0}^{\infty}na_nx^{n-1}=\sum_{n=0}^{\infty}nb_nx^{n-1},\quad -R<x<R\\in\quad which\quad R\leq R_a\,,\,R_b\]When \(x=0\) , we have \(a_1=b_1\). ··· ···Repeating the process , we will get \(a_n=b_n\).\(Q.E.D\quad \blacksquare\)This theorem will be a crucial point in our study of differentialequations , in which we develop power series solutions (For instance ,in theoretical physics , there's perturbation theory in quantummechanics).\hypertarget{ux25fbindeterminateformsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Indeterminate\quad Forms\)}{\textbackslash{}square\textbackslash{}quad Indeterminate\textbackslash{}quad Forms}}\label{ux25fbindeterminateformsuxa}}You can use the power-series representation of functions to prove\(L'H \hat{o} pital's\,\,\,Rule\) :\[\underset{x\to x_0}{lim}\frac{f(x)}{g(x)}=\underset{x\to x_0}{lim}\frac{f'(x)}{g'(x)}\](See exercise 1.2.12)\hypertarget{ux25fbinversionofpowerseriesuxa}{%\paragraph{\texorpdfstring{\(\square\quad Inversion\quad of\quad Power\quad Series\)}{\textbackslash{}square\textbackslash{}quad Inversion\textbackslash{}quad of\textbackslash{}quad Power\textbackslash{}quad Series}}\label{ux25fbinversionofpowerseriesuxa}}Consider that \(y-y_0=\sum_{n=1}^{\infty}a_n(x-x_0)^n\) , if we want toknow \(x-x_0=\sum_{n=1}^{\infty}b_n(y-y_0)^n\) , we need to equatecoefficients of \((x-x_0)^n\) on both sides of the given equation.\[b_1=\frac{1}{a_1}\\b_2=-\frac{a_2}{a_1^3}\\b_3=\frac{2a_2^2}{a_1^5}-\frac{a_3}{a_1^4}\\b_4=\frac{5a_2a_3}{a_1^6}-\frac{a_4}{a_1^5}-\frac{5a_2^3}{a_1^7}\\···\]\hypertarget{uxa7uxauxa713binomialtheoremuxa}{%\subsubsection{\texorpdfstring{\(\S1.3\quad Binomial\quad Theorem\)}{\textbackslash{}S1.3\textbackslash{}quad Binomial\textbackslash{}quad Theorem}}\label{uxa7uxauxa713binomialtheoremuxa}}Binomial series is a extremely significant application of the Maclaurinseries. Let \(f(x)=(1+x)^m\) , in which \(m\in\Re\). Then ,\[(1+x)^m=1+mx+\frac{m(m-1)}{2!}x^2+···+R_n\]For this function , the remainder is\[R_n=\frac{x^n}{n!}(1+\xi)^{m-n}m(m-1)···(m-n+1)\]with \(\xi\in(0,x)\).When \(x>0\) , for \(n>m\) , \((1+\xi)^{m-n}\) is a maximum for\(\xi>0\). So for \(x>0\) ,\(|R_n|\leq\frac{x^n}{n!}|m(m-1)···(m-n+1)|\) , with\(\underset{n\to\infty}{lim}R_n=0\) , when \(0\leq x<1\).Because the radius of convergence of a power series is the same forpositive and negative \(x\) , the binomial series converges for\(-1<x<1\). The endpoints cannot be determined.\textbf{Binomial Expansion :}\[(1+x)^m=1+mx+\frac{m(m-1)}{2!}x^2+\frac{m(m-1)(m-2)}{3!}x^3+···\]If \(m\) is a nonnegative integer , \(R_n\) for \(n>m\) vanishes for all\(x\) , corresponding to the fact that under those conditions\((1+x)^m\) is a finite sum.\textbf{Binomial Coefficients :}\begin{equation}\left\lgroup\begin{array}{lr}m\\n\end{array}\right\rgroup=\frac{m(m-1)···(m-n+1)}{n!}\end{equation}\begin{equation}(1+x)^m=\sum_{n=0}^{\infty}\left\lgroup\begin{array}{lr}m\\n\end{array}\right\rgroup x^n\end{equation}In which , when \(n=0\) ,\(\begin{equation}\left\lgroup\begin{array}{lr}m\\0\end{array}\right\rgroup =1\end{equation}\).1. When \(m\) is a positive integer ,\(\begin{equation}\left\lgroup\begin{array}{lr}m\\n\end{array}\right\rgroup =\frac{m!}{n!(m-n)!}\end{equation}\).That is\(C_m^n=\begin{equation}\left\lgroup\begin{array}{lr}m\\n\end{array}\right\rgroup\end{equation}\).2. For negative integer \(m\) , set \(m=-p\) , there is\begin{equation}\left\lgroup\begin{array}{lr}-p\\n\end{array}\right\rgroup=(-1)^n\frac{p(p+1)···(p+n-1)}{n!}=(-1)^n\frac{(p+n-1)!}{n!(p-1)!}\end{equation}3. For nonintegral \(m\) , it is convenient to use the\textbf{Pochhammer Symbol} , defined for general a and nonnegativeinteger \(n\) , as\[(a)_0=1\,,\quad(a)_1=a\,,\quad(a)_2=a(a+1)\,,\quad···\\(a)_{n+1}=a(a+1)···(a+n)\\\begin{equation}\left\lgroup\begin{array}{lr}m\\n\end{array}\right\rgroup=\frac{(m-n+1)_n}{n!}\end{equation}\]For addition , \(0!!=(-1)!!=1\) , because \((2n)!!=2^nn!\) , and\((2n-1)!!=\frac{(2n)!!}{2^nn!}\).\hypertarget{ux25fbgeneralizedbinomialexpansionuxa}{%\paragraph{\texorpdfstring{\(\square\quad Generalized\quad Binomial\quad Expansion\)}{\textbackslash{}square\textbackslash{}quad Generalized\textbackslash{}quad Binomial\textbackslash{}quad Expansion}}\label{ux25fbgeneralizedbinomialexpansionuxa}}1. For positive integer \(n\) , to polynomials ,\[(a_1+a_2+···+a_m)^n=\sum\frac{n!}{n_1!n_2!···n_m!}a_1^{n_1}a_2^{n_2}···a_m^{n_m}\]In which \(\sum_{i=1}^mn_i=n\).\begin{enumerate}\def\labelenumi{\arabic{enumi}.}\item  \begin{equation}  (\frac{d}{dx})^n(u(x)v(x))=\sum_{i=0}^{n}  \left\lgroup  \begin{array}{lr}  n\\i  \end{array}  \right\rgroup(\frac{d^iu(x)}{dx^i})(\frac{d^{n-i}v(x)}{dx^{n-i}})  \end{equation}\end{enumerate}\hypertarget{uxa7uxauxa714mathematicalinductionuxa}{%\subsubsection{\texorpdfstring{\(\S1.4\quad Mathematical\quad Induction\)}{\textbackslash{}S1.4\textbackslash{}quad Mathematical\textbackslash{}quad Induction}}\label{uxa7uxauxa714mathematicalinductionuxa}}If a relation is valid for an arbitrary value of some index \(n\) , thenit is also valid if \(n\) is replaced by \((n+1)\).\hypertarget{uxa7uxauxa715operationsonseriesexpansionsoffunctionsuxa}{%\subsubsection{\texorpdfstring{\(\S1.5\quad Operations\,\,on\,\,Series\,\,Expansions\,\,of\,\,Functions\)}{\textbackslash{}S1.5\textbackslash{}quad Operations\textbackslash{},\textbackslash{},on\textbackslash{},\textbackslash{},Series\textbackslash{},\textbackslash{},Expansions\textbackslash{},\textbackslash{},of\textbackslash{},\textbackslash{},Functions}}\label{uxa7uxauxa715operationsonseriesexpansionsoffunctionsuxa}}For example ,\begin{flalign}\frac{1}{1+x}=&1-x+x^2-x^3+···\\\overset{integral}{\Longrightarrow}ln(1+x)=&x-\frac{1}{2}x^2+\frac{1}{3}x^3-\frac{1}{4}x^4+···\end{flalign}\hypertarget{uxa7uxauxa716someimportantseriesuxa}{%\subsubsection{\texorpdfstring{\(\S1.6\quad Some\quad Important\quad Series\)}{\textbackslash{}S1.6\textbackslash{}quad Some\textbackslash{}quad Important\textbackslash{}quad Series}}\label{uxa7uxauxa716someimportantseriesuxa}}\begin{flalign}e^x=&\sum_{n=0}^{\infty}\frac{x^n}{n!}=1+x+\frac{1}{2}x^2+···\\sin(x)=&\sum_{n=0}^{\infty}\frac{(-1)^nx^{2n+1}}{(2n+1)!}=x-\frac{1}{6}x^3+···\\sinh(x)=&\sum_{n=0}^{\infty}\frac{x^{2n+1}}{(2n+1)!}=x+\frac{1}{6}x^3+···\\cos(x)=&\sum_{n=0}^{\infty}\frac{(-1)^nx^{2n}}{(2n)!}=1-\frac{1}{2}x^2+···\\cosh(x)=&\sum_{n=0}^{\infty}\frac{x^{2n}}{(2n)!}=1+\frac{1}{2}x^2+···\\\frac{1}{1-x}=&\sum_{n=0}^{\infty}x^n=1+x+···\\ln(1+x)=&\sum_{n=0}^{\infty}\frac{(-1)^{n-1}x^n}{n}=x-\frac{1}{2}x^2+···\\\end{flalign}\begin{equation}(1+x)^p=\sum_{n=0}^{\infty}\left\lgroup\begin{array}{lr}p\\n\end{array}\right\rgroup x^n=\sum_{n=0}^{\infty}\frac{(p-n+1)_n}{n!}x^n=1+\frac{p}{1!}x+\frac{p(p-1)}{2!}x^2+\cdots\end{equation}\hypertarget{uxa7uxauxa717vectorsuxa}{%\subsubsection{\texorpdfstring{\(\S1.7\quad Vectors\)}{\textbackslash{}S1.7\textbackslash{}quad Vectors}}\label{uxa7uxauxa717vectorsuxa}}Scalar is defined as quantity that has algebraic magnitude only.Vector is defined as quantity that has magnitude and direction. Vectorsdefined over a region are called vector fields.\hypertarget{ux25fbbasicpropertiesuxa-1}{%\paragraph{\texorpdfstring{\(\square\quad Basic\quad Properties\)}{\textbackslash{}square\textbackslash{}quad Basic\textbackslash{}quad Properties}}\label{ux25fbbasicpropertiesuxa-1}}Let's just skip this part ···\hypertarget{ux25fbdotscalarproductuxa}{%\paragraph{\texorpdfstring{\(\square\quad Dot(Scalar)\quad Product\)}{\textbackslash{}square\textbackslash{}quad Dot(Scalar)\textbackslash{}quad Product}}\label{ux25fbdotscalarproductuxa}}Algebraic formula :\(\vec{A}\cdot\vec{B}=\sum_iA_iB_i=\sum_iB_iA_i=\vec{B}\cdot\vec{A}\)( That is , if \(\vec{C}=\vec{A}+\vec{B}\) , then\(\vec{A}\cdot\vec{B}=\frac{1}{2}(|\vec{C}|^2-|\vec{A}|^2-|\vec{B}|^2)\))Geometric formula : \(\vec{A}\cdot\vec{B}=|\vec{A}||\vec{B}|cos\theta\), in which \(\theta=<\vec{A},\vec{B}>\).The projection of \(\vec{A}\) in direction of \(\vec{B}\) :\(\vec{A_b}=(\vec{A}\cdot\frac{\vec{B}}{|\vec{B}|})\frac{\vec{B}}{|\vec{B}|}\)Schwarz inequality : \(|\vec{A}\cdot\vec{B}|\leq|\vec{A}||\vec{B}|\)\hypertarget{ux25fborthogonalityuxa}{%\paragraph{\texorpdfstring{\(\square\quad Orthogonality\)}{\textbackslash{}square\textbackslash{}quad Orthogonality}}\label{ux25fborthogonalityuxa}}If \(\vec{A}、\vec{B}\neq0\) , then\[\vec{A}\cdot\vec{B}=0\iff\vec{A}、\vec{B}\,\,\,\,are\,\,orthogonal.\]\hypertarget{uxa7uxauxa718complexnumbersfunctionsuxa}{%\subsubsection{\texorpdfstring{\(\S1.8\quad Complex\quad Numbers\quad \&\quad Functions\)}{\textbackslash{}S1.8\textbackslash{}quad Complex\textbackslash{}quad Numbers\textbackslash{}quad \textbackslash{}\&\textbackslash{}quad Functions}}\label{uxa7uxauxa718complexnumbersfunctionsuxa}}\hypertarget{ux25fbbasicpropertiesuxa-2}{%\paragraph{\texorpdfstring{\(\square\quad Basic\quad Properties\)}{\textbackslash{}square\textbackslash{}quad Basic\textbackslash{}quad Properties}}\label{ux25fbbasicpropertiesuxa-2}}A complex number is an ordered pair of two real variables , \(z=(x,y)\)(the order is significant) , in which \(i=(0,1)\) is the imaginary unit.Addition : \(z_1+z_2=(x_1,y_1)+(x_2,y_2)=(x_1+x_2,y_1+y_2)\)Multiplication :\(z_1\cdot z_2=(x_1,y_1)\cdot(x_2,y_2)=(x_1x_2-y_1y_2,x_1y_2+x_2y_1)\)\begin{flalign}\Rightarrow& i^2=(0,1)\cdot(0,1)=(-1,0)=-1\\\Rightarrow& (x_1+iy_1)\cdot(x_2+iy_2)=(x_1x_2-y_1y_2)+i(x_1y_2+x_2y_1)\end{flalign}For historical reasons , \(i\) and its multiples are known as imaginarynumbers.The space of complex numbers , sometimes denoted \(\Z\) , bymathematicians , has the following formal properties :1. It is closed under addition and multiplication , meaning that if twocomplex numbers are added or multiplied , the result is also a complexnumber.2.It has a unique zero number , which when added to any complex numberleaves it unchanged and which , when multiplied with any complex numberyields zero.3.It has a unique unit number \(1\) , which when multiplied with anycomplex number leaves it unchanged.4.Every complex number \(z\) has an inverse under addition (known as\(-z\)) , and every nonzero \(z\) has an inverse under multiplication ,denoted \(z^{-1}\) or \(1/z\).5.It is closed under exponentiation : if \(u\) and \(v\) are complexnumbers , the \(u^v\) is also a complex number.Complex conjugation : \(z=x+iy\Longleftrightarrow z^*=x-iy\)\begin{flalign}\Rightarrow& z\cdot z^*=x^2+y^2\\\Rightarrow& |z|=\sqrt{z\cdot z^*}\end{flalign}Division :\[\frac{z'}{z}=\frac{z'\cdot z^*}{z\cdot z^*}=\frac{(x'+iy')(x-iy)}{x^2+y^2}=\frac{xx'+yy'}{x^2+y^2}+i\frac{xy'-x'y}{x^2+y^2}\]\hypertarget{ux25fbfunctionsinthecomplexdomainuxa}{%\paragraph{\texorpdfstring{\(\square\quad Functions\quad in\quad the\quad Complex\quad Domain\)}{\textbackslash{}square\textbackslash{}quad Functions\textbackslash{}quad in\textbackslash{}quad the\textbackslash{}quad Complex\textbackslash{}quad Domain}}\label{ux25fbfunctionsinthecomplexdomainuxa}}Among other things , that if a function is represented by a power series, we should , within the region of convergence of the power series , beable to use such series with complex values of the expansion variable.This is called the permanence of the algebraic form.\[e^z=1+z+\frac{1}{2!}z^2+\cdots\\\begin{flalign}e^{iz}=&1+(iz)+\frac{1}{2!}(iz)^2+\cdots\\=&(1-\frac{1}{2!}z^2+\cdots)+i(z-\frac{1}{3!}z^3+\cdots)\\=&cos(z)+isin(z)\end{flalign}\]which is called \textbf{Euler equation}.when \(z=x+iy\) , then \(f(z)=u(x,y)+iv(x,y)\) has real part\(\mathscr{Re}(f(z))=u(x,y)\) and imaginary part\(\mathscr{Im}(f(z))=v(x,y)\).\hypertarget{ux25fbpolarrepresentationuxa}{%\paragraph{\texorpdfstring{\(\square\quad Polar\quad Representation\)}{\textbackslash{}square\textbackslash{}quad Polar\textbackslash{}quad Representation}}\label{ux25fbpolarrepresentationuxa}}Skip that \(\cdots\)\(z=re^{i\theta}\) , \(r\) is called modulus , \(\theta\) is calledargument or phase. Since additon on an Argand diagram is analogous to\(2-D\) vector addition , it can be seen that\[||z|-|z'||\leq|z\pm z'|\leq|z|+|z'|\]Remember , \(w(z)\) is a mapping from \(xy\) plane to \(uv\) plane.\hypertarget{ux25fbcomplexnumbersofunitmagnitudeuxa}{%\paragraph{\texorpdfstring{\(\square\quad Complex\quad Numbers\quad of\quad Unit\quad Magnitude\)}{\textbackslash{}square\textbackslash{}quad Complex\textbackslash{}quad Numbers\textbackslash{}quad of\textbackslash{}quad Unit\textbackslash{}quad Magnitude}}\label{ux25fbcomplexnumbersofunitmagnitudeuxa}}They are on the unit circle.\hypertarget{ux25fbcircularhyperbolicfunctionsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Circular\quad \&\quad Hyperbolic\quad Functions\)}{\textbackslash{}square\textbackslash{}quad Circular\textbackslash{}quad \textbackslash{}\&\textbackslash{}quad Hyperbolic\textbackslash{}quad Functions}}\label{ux25fbcircularhyperbolicfunctionsuxa}}\begin{flalign}cos(\theta)=\frac{e^{i\theta}+e^{-i\theta}}{2}\,&,\qquad sin(\theta)=\frac{e^{i\theta}-e^{-i\theta}}{2}\\cosh(\theta)=\frac{e^{\theta}+e^{-\theta}}{2}\,&,\qquad sinh(\theta)=\frac{e^{\theta}-e^{-\theta}}{2}\\\\\Longrightarrow\qquad cosh(iz)=cos(z)\,&,\qquad sinh(iz)=isin(z)\\\\cos(n\theta)+isin(n\theta)&=(cos(\theta)+isin(\theta))^n\end{flalign}\begin{flalign}e^{iz}=isin(z)&+\sqrt{1-sin^2(z)}\\\Longrightarrow\qquad arcsin(z)=&-iln(iz+\sqrt{1-z^2})\\arctan(z)=&\frac{1}{2}iln(\frac{1-iz}{1+iz})\\arcsinh(z)=&ln(z+\sqrt{1+z^2})\\arctanh(z)=&\frac{1}{2}ln(\frac{1+z}{1-z})\end{flalign}\hypertarget{ux25fbpowerrootuxa}{%\paragraph{\texorpdfstring{\(\square\quad Power\quad \&\quad Root\)}{\textbackslash{}square\textbackslash{}quad Power\textbackslash{}quad \textbackslash{}\&\textbackslash{}quad Root}}\label{ux25fbpowerrootuxa}}The polar form is very convenient for expressing powers and roots ofcomplex numbers. Consider when \(z=re^{i\varphi}\) , then\[z^n=r^ne^{in\varphi}\\z^{1/n}=r^{1/n}e^{i(\varphi+2m\pi)/n}\\(m\in\Z)\]Actually , \(1/n\) root has \(n\) different values.\hypertarget{ux25fblogarithmuxa}{%\paragraph{\texorpdfstring{\(\square\quad Logarithm\)}{\textbackslash{}square\textbackslash{}quad Logarithm}}\label{ux25fblogarithmuxa}}\[ln(z)=ln(re^{i\theta})=ln(r)+i(\theta+2n\pi)\\(n\in\Z)\]\(\Longrightarrow\) \(ln(z)\) has infinite number of values.\hypertarget{uxa7uxauxa719derivativesextremauxa}{%\subsubsection{\texorpdfstring{\(\S1.9\quad Derivatives\quad \&\quad Extrema\)}{\textbackslash{}S1.9\textbackslash{}quad Derivatives\textbackslash{}quad \textbackslash{}\&\textbackslash{}quad Extrema}}\label{uxa7uxauxa719derivativesextremauxa}}Definition of derivative :\[\frac{df(x)}{dx}|_x=\underset{\epsilon\to0}{lim}\frac{f(x+\epsilon)-f(x)}{\epsilon}\]Variation \(\&\) differential : \(df=\frac{df}{dx}dx\)When \(f(x,y,z)\) , we have\(df=\frac{\partial f}{\partial x}dx+\frac{\partial f}{\partial y}dy+\frac{\partial f}{\partial z}dz\), in which \(\frac{\partial f}{\partial x}\) is called partialderivatives.Cross derivatives :\(\frac{\partial^2 f}{\partial x\partial y}=\frac{\partial^2 f}{\partial y\partial x}\)1.The chain rule :\[\frac{df}{ds}=\frac{\partial f}{\partial x}\frac{dx}{ds}+\frac{\partial f}{\partial y}\frac{dy}{ds}+\frac{\partial f}{\partial z}\frac{dz}{ds}\]2.Consider \(f=f(x,y)\) , then :\[(\frac{\partial f}{\partial x})_y(\frac{\partial x}{\partial y})_f(\frac{\partial y}{\partial f})_x=-1\]In Lagrangian mechanics , we often encounter formulas such as\[\frac{d}{dt}L(x,\dot{x},t)=\frac{\partial L}{\partial x}\dot{x}+\frac{\partial L}{\partial \dot{x}}\ddot{x}+\frac{\partial L}{\partial t}\]In which we need to distinguish between \(\frac{d}{dt}\) and\(\frac{\partial}{\partial t}\).\hypertarget{ux25fbstationarypointsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Stationary\quad Points\)}{\textbackslash{}square\textbackslash{}quad Stationary\textbackslash{}quad Points}}\label{ux25fbstationarypointsuxa}}If we want to know how a function \(f\) changes if we move in variousdirections in the space of the independent variables , we can use\[\frac{df}{ds}=\frac{\partial f}{\partial x}\frac{dx}{ds}+\frac{\partial f}{\partial y}\frac{dy}{ds}+\frac{\partial f}{\partial z}\frac{dz}{ds}\]In which the direction is given by \(\frac{dx_i}{ds}\).It is often to find the minimum of a function \(f\) of \(n\) variables\(x_i\) , \(i=1,2,\cdots,n\) , and a necessary but not sufficientcondition on its position is that \(\frac{df}{ds}=0\) , for \(ds\) inany direction. And this equals to \(\frac{\partial f}{\partial x_i}=0\), \(i=1,2,\cdots,n\).All points that satisfies the formula above are termed\textbf{stationary} :\begin{equation}\left\{\begin{array}{lr}\frac{d^2f}{ds^2}>0\Longrightarrow minimum\\\frac{d^2f}{ds^2}<0\Longrightarrow maximum\\else\Longrightarrow saddle\end{array}\right.\end{equation}\hypertarget{uxa7uxauxa7110evaluationofintegralsuxa}{%\subsubsection{\texorpdfstring{\(\S1.10\quad Evaluation\quad of\quad Integrals\)}{\textbackslash{}S1.10\textbackslash{}quad Evaluation\textbackslash{}quad of\textbackslash{}quad Integrals}}\label{uxa7uxauxa7110evaluationofintegralsuxa}}\textbf{\(\star\star\star\) Proficiency in the evaluation of integralsinvolves a mixture of experience , skill in pattern recognition , and afew tricks. \(\star\star\star\)}\hypertarget{ux25fbintegrationbypartsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Integration\quad by\quad Parts\)}{\textbackslash{}square\textbackslash{}quad Integration\textbackslash{}quad by\textbackslash{}quad Parts}}\label{ux25fbintegrationbypartsuxa}}Legendre Transformation :\begin{flalign}d(uv)=&\,udv+vdu\\\Longrightarrow udv=&\,d(uv)-vdu\\\Longrightarrow \int_a^budv=&\,uv|_a^b-\int_a^bvdu\end{flalign}\hypertarget{ux25fbspecialfunctionsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Special\quad Functions\)}{\textbackslash{}square\textbackslash{}quad Special\textbackslash{}quad Functions}}\label{ux25fbspecialfunctionsuxa}}\begin{longtable}[]{@{}lll@{}}\topruleFunctions & Definitions & Addition\tabularnewline\midrule\endheadGamma Function & \(\Gamma(x)=\int_0^{\infty}t^{x-1}e^{-t}dt\) & SeeChapter 13.\tabularnewlineFactorial (\(n\) integral) & \(n!=\Gamma(n+1)\) & /\tabularnewlineRiemann Zeta Function &\(\zeta(x)=\frac{1}{\Gamma(x)}\int_0^\infty\frac{t^{x-1}dt}{e^t-1}\) &See Chapter 1.\(\&\)12.\tabularnewlineExponential Integrals & \(E_n(x)=\int_1^\infty t^{-n}e^{-xt}dt\) &\(=\int_x^\infty t^{-n}e^{-t}dt\)\tabularnewline& \(Ei(x)=\int_{-\infty}^{x}t^{-1}e^{-t}dt\) &\(E_1(x)=-Ei(-x)\)\tabularnewlineSine Integral & \(Si(x)=-\int_x^{\infty}\frac{sin(t)}{t}dt\) &/\tabularnewlineCosine Integral & \(Ci(x)=-\int_x^{\infty}\frac{cos(t)}{t}dt\) &/\tabularnewlineError Functions & \(erf(x)=\frac{2}{\sqrt{\pi}}\int_0^xe^{-x^2}dt\) &\(erf(\infty)=1\)\tabularnewline& \(erfc(x)=\frac{2}{\sqrt{\pi}}\int_x^\infty e^{-x^2}dt\) &\(erfc(x)=1-erf(x)\)\tabularnewlineDilogarithm & \(Li_2(x)=-\int_0^x\frac{ln(1-t)}{t}dt\) &/\tabularnewline\bottomrule\end{longtable}\hypertarget{ux25fbothermethodsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Other\quad Methods\)}{\textbackslash{}square\textbackslash{}quad Other\textbackslash{}quad Methods}}\label{ux25fbothermethodsuxa}}An extremely powerful method for the evaluation of difinite integrals isthat of contour integration in the complex plane. But this method willbe presented in Chapter11. and not be dicussed here.1.Integrals can often be evaluated by methods that involve integrationor differentiation with respect to parameters , thereby obtainingrelations between known integrals and those whose values are beingsought.2.Many integrals can be evaluated by first converting them into infiniteseries , then manipulating the resulting series , and finally eitherevaluating the series or recognizing it as a special function.3.Simply using complex numbers aids in the evaluation of some integrals.4.Recursion is useful in obtaining formulas for a set of relatedintegrals.\hypertarget{ux25fbmultipleintegralsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Multiple\quad Integrals\)}{\textbackslash{}square\textbackslash{}quad Multiple\textbackslash{}quad Integrals}}\label{ux25fbmultipleintegralsuxa}}\begin{flalign}&\iint f(x,y)dxdy\\\\or\qquad &\int_{x_1}^{x_2}dx\int_{y_1(x)}^{y_2(x)}dy\cdot f(x,y)\\\\or\qquad &\int_S f(x,y)dA\end{flalign}In addition to the techniques available for integration in a singlevariable , multiple integrals provide further opportunities forevaluation based on changes in the order of integration and in thecoordinate system used in the integral.A significant change in the form of the \(2-D\) or \(3-D\) integrals cansometimes be accomplished by changing between Cartesian and polarcoordinate systems.\hypertarget{ux25fbremarkschangesofintegrationvariablesuxa}{%\paragraph{\texorpdfstring{\(\square\quad Remarks\,:\,Changes\,of\,Integration\,Variables\)}{\textbackslash{}square\textbackslash{}quad Remarks\textbackslash{},:\textbackslash{},Changes\textbackslash{},of\textbackslash{},Integration\textbackslash{},Variables}}\label{ux25fbremarkschangesofintegrationvariablesuxa}}In a \(1-D\) integration , a change in the integration variable from ,say , \(x\) to \(y(x)\) involves two adjustments :1.\(dx\longrightarrow(\frac{dx}{dy})dy\)2.\(x_1,x_2\longrightarrow y(x_1),y(x_2)\)If \(y(x)\) and \(x(y)\) is not single-valued , the process becomes morecomplicated , and we will not discuss it here.For multiple integrals , we use \textbf{Jacobian}. For\(dxdy\longrightarrow Jdudv\) ,\(J=\frac{\partial(x,y)}{\partial(u,v)}\).The computation of Jacobian will be discussed in Section4.4. Here ,remember to determinate the transformed region.\hypertarget{uxa7uxauxa7111diracdeltafunctionuxa}{%\subsubsection{\texorpdfstring{\(\S1.11\quad Dirac\quad Delta\quad Function\)}{\textbackslash{}S1.11\textbackslash{}quad Dirac\textbackslash{}quad Delta\textbackslash{}quad Function}}\label{uxa7uxauxa7111diracdeltafunctionuxa}}Definition :\[\delta(x)=0\,,\,x\neq0\\f(0)=\int_a^bf(x)\delta(x)dx\,\,,\,\,(a<0<b)\\\int_{-\infty}^{\infty}\delta(x)dx=1\]\textbf{No such function exists , (in the usual sense).} However , thecrucial property can be developed rigorously as the limit of a sequenceof functions. The common seen examples are as follows :\begin{longtable}[]{@{}ll@{}}\topruleExamples & Properties\tabularnewline\midrule\endhead\(\begin{equation}\delta_n(x)=\left\{\begin{array}{lr}0\,,\,(-\infty,-\frac{1}{2n})\cup(\frac{1}{2n},\infty)\\n\,,\,(-\frac{1}{2n},\frac{1}{2n})\end{array}\right.\end{equation}\)& easy to integrate\tabularnewline\(\delta_n(x)=\frac{n}{\sqrt{\pi}}e^{-n^2x^2}\) & its derivatives leadsto Hermite Polynomials\tabularnewline\(\delta_n(x)=\frac{n}{\pi}\frac{1}{1+n^2x^2}\) & /\tabularnewline\(\delta_n(x)=\frac{sin(nx)}{\pi x}=\frac{1}{2\pi}\int_{-n}^ne^{-ixt}dt\)& Fourier analysis or quantum mechanics\tabularnewline& Dirichlet Kernel :\(\frac{sin[(n+\frac{1}{2})x]}{2\pi sin(\frac{1}{2}x)}\)\tabularnewline\bottomrule\end{longtable}They are of different uses as above.For most physical purposes , the forms describing delta functions arequite adequate. However, from a mathematical point of view , the limits\(\underset{n\to\infty}{lim}\delta_n(x)\) do not exist. To avoid thedifficulty , label \(\delta(x)\) a distribution , and write :\[\int_{-\infty}^{\infty}\delta(x)f(x)dx=\underset{n\to\infty}{lim}\int_{-\infty}^{\infty}\delta_n(x)f(x)dx\]\hypertarget{ux25fbpropertiesofux3b4xuxa}{%\paragraph{\texorpdfstring{\(\square\quad Properties\quad of\quad \delta(x)\)}{\textbackslash{}square\textbackslash{}quad Properties\textbackslash{}quad of\textbackslash{}quad \textbackslash{}delta(x)}}\label{ux25fbpropertiesofux3b4xuxa}}\(\bullet\) \(\delta(-x)=\delta(x)\)\(\bullet\) \(\delta(ax)=\frac{1}{|a|}\delta(x)\)Proof :\[\int_{-\infty}^{\infty}f(x)\delta(ax)dx=\frac{1}{|a|}\int_{-\infty}^{\infty}f(\frac{y}{|a|})\delta(y)dy=\frac{f(0)}{|a|}\]\(\bullet\) \(\int_{-\infty}^{\infty}f(x)\delta(x-x_0)dx=f(x_0)\)\(\bullet\) If the argument of \(\delta(x)\) is a function \(g(x)\) withsimple zeros at points \(a_i\) on the real axis (and therefore\(g'(a_i)\neq0\)) , then\[\delta(g(x))=\sum_i\frac{\delta(x-a_i)}{|g'(a_i)|}\]Proof :\[\int_{-\infty}^{\infty}f(x)\delta(x)dx=\sum_i\int_{a_i-\varepsilon}^{a_i+\varepsilon}f(x)\delta[(x-a_i)g'(a_i)]dx\\(\varepsilon\to0)\]\(\bullet\) Derivative of delta function :\[\int_{-\infty}^{\infty}f(x)\delta'(x-x_0)dx=-\int_{-\infty}^{\infty}f'(x)\delta(x-x_0)dx=-f'(x_0)\]This is the definition of \(\delta'(x-x_0)\).\(\bullet\) In three dimensions , the delta function \(\delta(\vec{r})\)is intepreted as \(\delta(x)\delta(y)\delta(z)\) , irrespective of thecoordinate system in use. Thus , in spherical polar coordinates ,\[\iiint f(\vec{r_2})\delta(\vec{r_2}-\vec{r_1})r_2^2dr_2\cdot sin\theta_2d\theta_2\cdot d\varphi=f(\vec{r_1})\]\(\bullet\)\(\delta(t-x)=\frac{1}{2\pi}\int_{-\infty}^{\infty}e^{i\omega(t-x)}d\omega\)(See Chapter20. , Fourier Integrals)\(\bullet\) Expansions of \(\delta(x)\) are addressed in Chapter5.(Example5.1.7).\hypertarget{ux25fbkroneckerdeltauxa}{%\paragraph{\texorpdfstring{\(\square\quad Kronecker\quad Delta\)}{\textbackslash{}square\textbackslash{}quad Kronecker\textbackslash{}quad Delta}}\label{ux25fbkroneckerdeltauxa}}The discrete analog of the Dirac delta function ,\begin{equation}\delta_{ij}=\left\{\begin{array}{lr}1\,,\,i=j\\0\,,\,i\neq j\end{array}\right.\end{equation}Usage examples :\[\sum_{i,j}f_{ij}\delta_{ij}=\sum_if_{ii}\\or\quad c_n=\frac{1}{1+\delta_{n0}}\frac{2\pi}{L}\]\hypertarget{ux1d4bduxaux1d4b6uxaux1d4c5uxaux1d4c9uxaux212fuxaux1d4c7uxaux212fuxaux1d4c9uxaux212fuxaux1d4c7uxaux1d4c2uxaux1d4beuxaux1d4c3uxaux1d4b6uxaux1d4c3uxaux1d4c9uxaux1d4c8uxaux1d4b6uxaux1d4c9uxaux1d4c7uxaux1d4beuxaux1d4b8uxaux212fuxaux1d4c8uxachapter2determinantsmatricesuxa}{%\subsection{\texorpdfstring{\(\mathscr{Chapter2\quad Determinants\quad \&\quad Matrices}\)}{\textbackslash{}mathscr\{Chapter2\textbackslash{}quad Determinants\textbackslash{}quad \textbackslash{}\&\textbackslash{}quad Matrices\}}}\label{ux1d4bduxaux1d4b6uxaux1d4c5uxaux1d4c9uxaux212fuxaux1d4c7uxaux212fuxaux1d4c9uxaux212fuxaux1d4c7uxaux1d4c2uxaux1d4beuxaux1d4c3uxaux1d4b6uxaux1d4c3uxaux1d4c9uxaux1d4c8uxaux1d4b6uxaux1d4c9uxaux1d4c7uxaux1d4beuxaux1d4b8uxaux212fuxaux1d4c8uxachapter2determinantsmatricesuxa}}\hypertarget{uxa7uxauxa721diterminantsuxa}{%\subsubsection{\texorpdfstring{\(\S2.1\quad Diterminants\)}{\textbackslash{}S2.1\textbackslash{}quad Diterminants}}\label{uxa7uxauxa721diterminantsuxa}}We begin the study of matrices by solving linear equations that willlead us to determinants and matrices. The concept of determinant and thenotation were introduced by the renowned German mathematician andphilosopher \(Gottfried\,\,\,Wilhelm\,\,\,von\,\,\,Leibniz\).\hypertarget{ux25fbhomogeneouslinearequationsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Homogeneous\quad Linear\quad Equations\)}{\textbackslash{}square\textbackslash{}quad Homogeneous\textbackslash{}quad Linear\textbackslash{}quad Equations}}\label{ux25fbhomogeneouslinearequationsuxa}}Suppose three unknowns \(x_1,x_2,x_3\) (or \(n\) equations with \(n\)unknowns) :\begin{equation}\left\{\begin{array}{lr}a_1x_1+a_2x_2+a_3x_3=0\\b_1x_1+b_2x_2+b_3x_3=0\\c_1x_1+c_2x_2+c_3x_3=0\end{array}\right.\end{equation}The problem is to determine under what conditions there is any solution, apart from the trivial one \(x_1=x_2=x_3=0\). Using vectors , we have\(\vec{a}\cdot\vec{x}=0\,,\,\vec{b}\cdot\vec{y}=0\,,\,\vec{c}\cdot\vec{z}=0\).These three vector equations have the geometrical intepretation that\(x\) is orthogonal to \(\vec{a}\,,\,\vec{b}\,,\,\vec{c}\).If the volume spanned by \(\vec{a}\,,\,\vec{b}\,,\,\vec{c}\) given bydeterminant (or triple scalar product)\[D_3=(\vec{a}\cross\vec{b})\cdot\vec{c}=det(\vec{a}\,,\,\vec{b}\,,\,\vec{c})=\left\vert\begin{matrix}a_1&a_2&a_3\\b_1&b_2&b_3\\c_1&c_2&c_3\end{matrix}\right\vert\]is not zero , then there is the only trivial solution \(\vec{x}=0\).Conversely , if the aforementional determinant of the coefficientvanishes , then one of the row vectors is a combination of the othertwo. \(\vec{c}\subseteq plane(\vec{a}\cross\vec{b})\) , only ratios of\(x_i\) are relevant.\[\frac{x_1}{x_3}=\frac{a_2b_3-a_3b_2}{a_1b_2-a_2b_1}\qquad\frac{x_2}{x_3}=-\frac{a_1b_3-a_3b_1}{a_1b_2-a_2b_1}\]This is \textbf{Cramer's Rule} for homogeneous linear equation.\hypertarget{ux25fbinhomogeneouslinearequationuxa}{%\paragraph{\texorpdfstring{\(\square\quad Inhomogeneous\quad Linear\quad Equation\)}{\textbackslash{}square\textbackslash{}quad Inhomogeneous\textbackslash{}quad Linear\textbackslash{}quad Equation}}\label{ux25fbinhomogeneouslinearequationuxa}}Simple example :\begin{equation}\left\{\begin{array}{lr}a_1x_1+a_2x_2=a_3\\b_1x_1+b_2x_2=b_3\end{array}\right.\end{equation}\[\Longrightarrowx_1=\frac{\left\vert\begin{matrix}a_3&a_2\\b_3&b_2\end{matrix}\right\vert}{\left\vert\begin{matrix}a_1&a_2\\b_1&b_2\end{matrix}\right\vert}\qquadx_2=\frac{\left\vert\begin{matrix}a_3&a_1\\b_3&b_1\end{matrix}\right\vert}{\left\vert\begin{matrix}a_1&a_2\\b_1&b_2\end{matrix}\right\vert}\]This is \textbf{Cramer's Rule} for inhomogeneous linear equation.\hypertarget{ux25fbdefinitionsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Definitions\)}{\textbackslash{}square\textbackslash{}quad Definitions}}\label{ux25fbdefinitionsuxa}}Before defining a determinant , we need to introduce some relatedconcepts and definitions.\(\bullet\) When we write two-dimensional (\(2-D\)) arrays of items , weidentify the item in the \(n\)th horizontal row and the \(m\)th verticalcolumn by the index set \(n,m\) ; note that the row index isconventionally written first.\(\bullet\) Starting from a set of \(n\) objects in some reference order(e.g. , the number sequence \(1,2,3,\cdots,n\)) , we can make apermutation of them to some other order ; the total number of distinctpermutations that are possible is \(n!\) (choose the first object \(n\)ways , then choose the second in \(n-1\) ways , etc.).\(\bullet\) Every permutation of \(n\) objects can be reached from thereference order by a succession of pairwise interchanges (e.g. ,\(1234\to4132\) can be reached by the successive steps\(1234\to1432\to4132\)). Although the number of pairwise interchangesneeded for a given permutation depends on the path (compare the aboveexample with \(1234\to1243\to1423\to4123\to4132\)) , for a givenpermutation the number of interchanges will always either be\textbf{even} or \textbf{odd}. Thus a permutation can be identified ashaving either even or odd parity.\(\bullet\) It is convenient to introduce the \textbf{Levi-Civitasymbol} , which for an \(n\)-object system is denoted by\(\varepsilon_{ij...}\) , where \(\varepsilon\) has \(n\) subscripts ,each of which identifies one of the objects.\begin{flalign}\varepsilon_{ij...}=&\,+1\,,\,ij...\,an\,\,\,even\,\,\,permutation\,,\\=&\,-1\,,\,ij...\,an\,\,\,odd\,\,\,permutation\,,\\=&\,0\,,\,ij...\,not\,\,\,a\,\,\,permutation.\end{flalign}We now define a determinant of order \(n\) to be an \(n\cross n\) squarearray of numbers (or functions) , with the array conventionally writtenwithin vertical bars (not parentheses , braces , or any other type ofbrackets) , as follows :\[D_n=\left\vert\begin{matrix}a_{11}&a_{12}&\cdots&a_{1n}\\a_{21}&a_{22}&\cdots&a_{2n}\\a_{31}&a_{32}&\cdots&a_{3n}\\\cdots&\cdots&\cdots&\cdots\\a_{n1}&a_{n2}&\cdots&a_{nn}\end{matrix}\right\vert.\]The determinant \(D_n\) has a value\(D_n=\underset{ij...}{\sum}\varepsilon_{ij...}a_{1i}a_{2j}\cdots\) .\hypertarget{ux25fbpropertiesofdeterminantsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Properties\quad of\quad Determinants\)}{\textbackslash{}square\textbackslash{}quad Properties\textbackslash{}quad of\textbackslash{}quad Determinants}}\label{ux25fbpropertiesofdeterminantsuxa}}Take determinants of order \(3\) for example.\[\left\vert\begin{matrix}a_{11}&a_{12}&a_{13}\\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33}\end{matrix}\right\vert=-\left\vert\begin{matrix}a_{12}&a_{11}&a_{13}\\a_{22}&a_{21}&a_{23}\\a_{32}&a_{31}&a_{33}\end{matrix}\right\vert=\left\vert\begin{matrix}a_{11}&a_{21}&a_{31}\\a_{12}&a_{22}&a_{32}\\a_{13}&a_{23}&a_{33}\end{matrix}\right\vert\\\\k\left\vert\begin{matrix}a_{11}&a_{12}&a_{13}\\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33}\end{matrix}\right\vert=\left\vert\begin{matrix}ka_{11}&a_{12}&a_{13}\\ka_{21}&a_{22}&a_{23}\\ka_{31}&a_{32}&a_{33}\end{matrix}\right\vert=\left\vert\begin{matrix}ka_{11}&ka_{12}&ka_{13}\\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33}\end{matrix}\right\vert\\\\\left\vert\begin{matrix}a_{11}+b_1&a_{12}&a_{13}\\a_{21}+b_2&a_{22}&a_{23}\\a_{31}+b_3&a_{32}&a_{33}\end{matrix}\right\vert=\left\vert\begin{matrix}a_{11}&a_{12}&a_{13}\\a_{21}&a_{22}&a_{23}\\a_{31}&a_{32}&a_{33}\end{matrix}\right\vert+\left\vert\begin{matrix}b_1&a_{12}&a_{13}\\b_2&a_{22}&a_{23}\\b_3&a_{32}&a_{33}\end{matrix}\right\vert\]\(\bullet\) Any determinant with two rows equal , or two columns equal ,has the value zero. To prove this , interchange the two identical rowsor columns ; the determinant both remains the same and changes sign ,and therefore must have the value zero.\(\bullet\) An extension of the above is that if two rows (or columns)are proportional , the determinant is zero.\(\bullet\) The value of a determinant is unchanged if a multiple of onerow is added (column by column) to another row or if a multiple of onecolumn is added (row by row) to another column.\(\bullet\) If each element in a row or each element in a column is zero, the determinant has the value zero.\hypertarget{ux25fblaplaciandevelopmentbyminoruxa}{%\paragraph{\texorpdfstring{\(\square\quad Laplacian\quad Development\quad by\quad Minor\)}{\textbackslash{}square\textbackslash{}quad Laplacian\textbackslash{}quad Development\textbackslash{}quad by\textbackslash{}quad Minor}}\label{ux25fblaplaciandevelopmentbyminoruxa}}The fact that a determinant of order \(n\) expands into \(n!\) termsmeans that it is important to identify efficient means for determinantevaluation. One approach is to expand in terms of minors. The minorcorresponding to \(a_{ij}\) , denoted \(M_{ij}\) , or \(M_{ij}(a)\) ifwe need to identify \(M\) as coming from the \(a_{ij}\) , is thedeterminant (of order \(n-1\)) produced by stiking out row \(i\) andcolumn \(j\) of the original determinant. And we get\[D_n=\sum_{j=1}^{n}a_{ij}(-1)^{i+j}M_{ij}\]\hypertarget{ux25fblinearequationsystemsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Linear\quad Equation\quad Systems\)}{\textbackslash{}square\textbackslash{}quad Linear\textbackslash{}quad Equation\textbackslash{}quad Systems}}\label{ux25fblinearequationsystemsuxa}}For equation\begin{equation}\left\{\begin{array}{lr}a_1x_1+a_2x_2+a_3x_3=h_1\\b_1x_1+b_2x_2+b_3x_3=h_2\\c_1x_1+c_2x_2+c_3x_3=h_3\end{array}\right.\end{equation}We define\[D=\left\vert\begin{matrix}a_1&a_2&a_3\\b_1&b_2&b_3\\c_1&c_2&c_3\end{matrix}\right\vert.\]Then we have\begin{flalign}x_1D=&\,\left\vert\begin{matrix}a_1x_1&a_2&a_3\\b_1x_1&b_2&b_3\\c_1x_1&c_2&c_3\end{matrix}\right\vert\\\\=&\,\left\vert\begin{matrix}a_1x_1+a_2x_2+a_3x_3&a_2&a_3\\b_1x_1+b_2x_2+b_3x_3&b_2&b_3\\c_1x_1+c_2x_2+c_3x_3&c_2&c_3\end{matrix}\right\vert\\\\=&\,\left\vert\begin{matrix}h_1&a_2&a_3\\h_2&b_2&b_3\\h_3&c_2&c_3\end{matrix}\right\vert\\\\\Longrightarrow\quad x_1=\frac{1}{D}\left\vert\begin{matrix}h_1&a_2&a_3\\h_2&b_2&b_3\\h_3&c_2&c_3\end{matrix}\right\vert,\,&\,x_2=\frac{1}{D}\left\vert\begin{matrix}a_1&h_1&a_3\\b_1&h_2&b_3\\c_1&h_3&c_3\end{matrix}\right\vert,\,x_3=\frac{1}{D}\left\vert\begin{matrix}a_1&a_2&h_1\\b_1&b_2&h_2\\c_1&c_2&h_3\end{matrix}\right\vert\end{flalign}This is the \textbf{Cramer's Rule}.If \(D\) is nonzero , the above construction of the \(x_i\) isdefinitive and unique , so that there will be exactly one solution tothe equation set.\hypertarget{ux25fbdeterminantslineardependenceuxa}{%\paragraph{\texorpdfstring{\(\square\quad Determinants\quad \&\quad Linear\quad Dependence\)}{\textbackslash{}square\textbackslash{}quad Determinants\textbackslash{}quad \textbackslash{}\&\textbackslash{}quad Linear\textbackslash{}quad Dependence}}\label{ux25fbdeterminantslineardependenceuxa}}If the coefficients of \(n\) linear forms in \(n\) variables form anonzero determinant , the forms are linearly independent ; if thedeterminant of the coefficients is zero , the forms exhibit lineardependence.\hypertarget{ux25fblinearlydependentequationsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Linearly\quad Dependent\quad Equations\)}{\textbackslash{}square\textbackslash{}quad Linearly\textbackslash{}quad Dependent\textbackslash{}quad Equations}}\label{ux25fblinearlydependentequationsuxa}}\hypertarget{situation-uxa1uxa}{%\subparagraph{\texorpdfstring{Situation\(1\)}{Situation 1}}\label{situation-uxa1uxa}}All the equations are homogeneous (which means all the right hand sidequantities \( h_i\) are zero). Then , one or more of the equations inthe set will be equivalent to linear combinations of others , and wewill have less than \(n\) equations in our \(n\) variables. We can thenassign one (or in some cases , more than one) variable an arbitraryvalue , obtaining the others as functions of the assigned variables. Wethus have a \textbf{manifold} (i.e. , a parameterized set) of solutionsto our equation system.\hypertarget{situation-uxa2uxa}{%\subparagraph{\texorpdfstring{Situation\(2\)}{Situation 2}}\label{situation-uxa2uxa}}A second case is where we have (or combine equations so that we have)the same linear form in two equations , but with different values of theright-hand quantities \(h_i\). In that case the equations are mutuallyinconsistent , and the equation system has no solution.\hypertarget{situation-uxa3uxa}{%\subparagraph{\texorpdfstring{Situation\(3\)}{Situation 3}}\label{situation-uxa3uxa}}A third , related case , is where we have a duplicated linear form , butwith a common value of \(h_i\). This also leads to a solution manifold.\hypertarget{ux25fbnumericalevaluationuxa}{%\paragraph{\texorpdfstring{\(\square\quad Numerical\quad Evaluation\)}{\textbackslash{}square\textbackslash{}quad Numerical\textbackslash{}quad Evaluation}}\label{ux25fbnumericalevaluationuxa}}There are many methods to evaluate determinants , even using computers.We use the \textbf{Gauss Elimination} to calculate determinants , whichis a versatile procedure that can be used for evaluating determinants,for solving linear equation systems, and (as we will see later) even formatrix inversion.Gauss Elimination : make the determinant into a form that all theentries in the lower triangle of the determinant. Then the onlyeffective part is the product of thediagonal elements.\hypertarget{uxa7uxauxa722matricesuxa}{%\subsubsection{\texorpdfstring{\(\S2.2\quad Matrices\)}{\textbackslash{}S2.2\textbackslash{}quad Matrices}}\label{uxa7uxauxa722matricesuxa}}Matrices are \(2-D\) arrays of numbers or functions that obey the lawsthat define \textbf{matrix algebra}.\hypertarget{ux25fbbasicdefinitionsuxa}{%\paragraph{\texorpdfstring{\(\square\quad Basic\quad Definitions\)}{\textbackslash{}square\textbackslash{}quad Basic\textbackslash{}quad Definitions}}\label{ux25fbbasicdefinitionsuxa}}A matrix is a set of numbers or functions in a \(2-D\) square orrectangular array. A matrix with \(m\) (horizontal) rows and \(n\)(vertical) columns is known as an \(m\cross n\) matrix. When weintroduced determinants , when row and column indices or dimensions arementioned together , it is customary to write the row indicaters first.A matrix for which \(n=m\) is termed \textbf{square}; One consisting ofa single column (an \(m\cross1\) matrix) is often called a\textbf{column vector} , while a matrix with only one row (therefore\(1\cross n\)) is a \textbf{row vector}.\hypertarget{ux25fbequalityuxa}{%\paragraph{\texorpdfstring{\(\square\quad Equality\)}{\textbackslash{}square\textbackslash{}quad Equality}}\label{ux25fbequalityuxa}}If \(A\) and \(B\) are matrices , \(A=B\) only if \(a_{ij}=b_{ij}\) forall values of \(i\) and \(j\). A necessary but not sufficient conditionfor equality is that both matrices have the same dimensions.\hypertarget{ux25fbadditionsubtractionuxa}{%\paragraph{\texorpdfstring{\(\square\quad Addition\,\,,\quad Subtraction\)}{\textbackslash{}square\textbackslash{}quad Addition\textbackslash{},\textbackslash{},,\textbackslash{}quad Subtraction}}\label{ux25fbadditionsubtractionuxa}}Addition and subtraction are defined only for matrices \(A\) and \(B\)of the same dimensions , in which case \(A\pm B=C\) , with\(c_{ij}=a_{ij}\pm b_{ij}\) for all values of \(i\) and \(j\). Additionis \textbf{commutative} (\(A+B=B+A\)) and also \textbf{associative}(\((A+B)+C=A+(B+C)\)). A matrix with all elements zero , called a\textbf{null matrix} or \textbf{zero matrix} , can either be written as\(O\) or as a simple zero. Thus for all \(A\) ,\[A+0=0+A=A\]\hypertarget{ux25fbmultiplicationbyascalaruxa}{%\paragraph{\texorpdfstring{\(\square\quad Multiplication\quad (by\quad a\quad Scalar)\)}{\textbackslash{}square\textbackslash{}quad Multiplication\textbackslash{}quad (by\textbackslash{}quad a\textbackslash{}quad Scalar)}}\label{ux25fbmultiplicationbyascalaruxa}}Here we have \(B=\alpha A\) , with \(b_{ij}=\alpha a_{ij}\) for allvalues of \(i\) and \(j\). This operation is commutative , with\(\alpha A=A\alpha\).Note that the definition of multiplication by a scalar causes\textbf{each} element of marix \(A\) to be multiplied by the scalarfactor , so there is\[det(\alpha A)=\alpha^ndet(A)\]\hypertarget{ux25fbmatrixmultiplicationinnerproductuxa}{%\paragraph{\texorpdfstring{\(\square\quad Matrix\quad Multiplication\quad (Inner\quad Product)\)}{\textbackslash{}square\textbackslash{}quad Matrix\textbackslash{}quad Multiplication\textbackslash{}quad (Inner\textbackslash{}quad Product)}}\label{ux25fbmatrixmultiplicationinnerproductuxa}}\textbf{Matrix multiplication} is not an element-by-element operationlike addition or multiplication by a scalar. The \textbf{inner product}of matrices \(A\) and \(B\) is defined as\[AB=C\,\,,\quad with\quad c_{ij}=\sum_ka_{ik}b_{kj}\]This definition causes the \(ij\) element of \(C\) to be formed from theentire \(i\)th row of \(A\) and the entire \(j\)th column of \(B\). Andas you can realize , \(AB\neq BA\).It is useful to define the \textbf{commutator} of \(A\) and \(B\) ,\[[A,B]=AB-BA\]which , as stated above , will in many cases be nonzero.But , matrix multiplication is \textbf{associative} , meaning that\(A(BC)=(AB)C\).\hypertarget{ux25fbunitmatrixuxa}{%\paragraph{\texorpdfstring{\(\square\quad Unit\quad Matrix\)}{\textbackslash{}square\textbackslash{}quad Unit\textbackslash{}quad Matrix}}\label{ux25fbunitmatrixuxa}}By direct matrix multiplication , it is possible to show that a squarematrix with elements of value unity on its \textbf{principal diagonal}(the elements \((i,j)\) with \(i=j\)) , and zeros everywhere else , willleave unchanged any matrix with which it can be multiplied. For example, the \(3\cross3\) unit matrix has the form\[\left\lgroup\begin{array}{lr}1&0&0\\0&1&0\\0&0&1\end{array}\right\rgroup\]\hypertarget{ux1d4c5uxaux1d4c5uxaux212fuxaux1d4c3uxaux1d4b9uxaux1d4beuxaux1d4cduxaux2134uxaux1d4c7uxaux1d4b9uxaux1d4c8uxaappendix1wordsuxa}{%\subsection{\texorpdfstring{\(\mathscr{Appendix1\quad Words}\)}{\textbackslash{}mathscr\{Appendix1\textbackslash{}quad Words\}}}\label{ux1d4c5uxaux1d4c5uxaux212fuxaux1d4c3uxaux1d4b9uxaux1d4beuxaux1d4cduxaux2134uxaux1d4c7uxaux1d4b9uxaux1d4c8uxaappendix1wordsuxa}}preliminary n. (pl. preliminaries) 初步crucial adj. 至关重要的，极好的monotonic adj. 单调的termwise adv./adj. 逐项地/的induction n. 归纳法duplicated adj. 重复的\end{document}]]></content>
    
    
    
    <tags>
      
      <tag>Physics</tag>
      
      <tag>math</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/03/22/hello-world/"/>
    <url>/2024/03/22/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start">Quick Start</h2><h3 id="Create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
