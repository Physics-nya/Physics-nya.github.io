

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/Physics-nya.github.io/physics_nya.jpg">
  <link rel="icon" href="/Physics-nya.github.io/physics_nya.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Physics-nya">
  <meta name="keywords" content="">
  
    <meta name="description" content="$$\mathscr{Notes,, on},,\mathscr{Mathematical}\\mathscr{Methods},,\mathscr{for},,\mathscr{Physicists}$$$$\mathscr{Chapter1\quad Mathematical\quad Preliminaries}$$$$ \S1.1\quad Infinite\quad Series$$">
<meta property="og:type" content="website">
<meta property="og:title" content="notes">
<meta property="og:url" content="http://physics-nya.github.io/notes/">
<meta property="og:site_name" content="Physics-nya&#39;s Blog">
<meta property="og:description" content="$$\mathscr{Notes,, on},,\mathscr{Mathematical}\\mathscr{Methods},,\mathscr{for},,\mathscr{Physicists}$$$$\mathscr{Chapter1\quad Mathematical\quad Preliminaries}$$$$ \S1.1\quad Infinite\quad Series$$">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-03-26T12:30:33.000Z">
<meta property="article:modified_time" content="2024-03-26T12:59:19.442Z">
<meta property="article:author" content="Physics-nya">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>notes - Physics-nya&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"physics-nya.github.io","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.1.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 60vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Physics-nya</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Notes of /Mathematical Methods for Physicists/"></span>
          
        </div>

        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      <div class="container nopadding-x-md">
        <div id="board"
          >
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                

<article class="page-content">
  <div class="markdown-body">

<h1 id="mathscr-Notes-on-mathscr-Mathematical-mathscr-Methods-mathscr-for-mathscr-Physicists"><a href="#mathscr-Notes-on-mathscr-Mathematical-mathscr-Methods-mathscr-for-mathscr-Physicists" class="headerlink" title="$$\mathscr{Notes,, on},,\mathscr{Mathematical}\\mathscr{Methods},,\mathscr{for},,\mathscr{Physicists}$$"></a>$$\mathscr{Notes,, on},,\mathscr{Mathematical}\\mathscr{Methods},,\mathscr{for},,\mathscr{Physicists}$$</h1><h2 id="mathscr-Chapter1-quad-Mathematical-quad-Preliminaries"><a href="#mathscr-Chapter1-quad-Mathematical-quad-Preliminaries" class="headerlink" title="$$\mathscr{Chapter1\quad Mathematical\quad Preliminaries}$$"></a>$$\mathscr{Chapter1\quad Mathematical\quad Preliminaries}$$</h2><h3 id="S1-1-quad-Infinite-quad-Series"><a href="#S1-1-quad-Infinite-quad-Series" class="headerlink" title="$$ \S1.1\quad Infinite\quad Series$$"></a>$$ \S1.1\quad Infinite\quad Series$$</h3><h4 id="square-quad-Comparison-quad-Test"><a href="#square-quad-Comparison-quad-Test" class="headerlink" title="$$\square\quad Comparison\quad Test$$"></a>$$\square\quad Comparison\quad Test$$</h4><p>​    Consider a convergent series {$$a_n$$} , we can use {$$a_n$$} to study the convergence of series {$$u_n$$} :</p>
<p>​    $$0\leq u_n \leq a_n \Rightarrow $$ {$$u_n$$} is convergent.</p>
<p>​    Similarly , consider a divergent series {$$a_n$$} , we can use {$$a_n$$} to study the convergence of series {$$u_n$$} :</p>
<p>​    $$u_n \geq a_n \geq 0 \Rightarrow$$ {$$u_n$$} is divergent.</p>
<h4 id="square-quad-Cauchy-quad-Root-quad-Test"><a href="#square-quad-Cauchy-quad-Root-quad-Test" class="headerlink" title="$$\square\quad Cauchy\quad Root\quad Test$$"></a>$$\square\quad Cauchy\quad Root\quad Test$$</h4><p>​    $$(a_n)^{1&#x2F;n}\leq r &lt; 1 \Rightarrow$$ {$$a_n$$} is convergent.</p>
<p>​    $$(a_n)^{1&#x2F;n} \geq 1 \Rightarrow$$ {$$a_n$$} is divergent.</p>
<h4 id="square-quad-d’Alembert-quad-or-quad-Cauchy-quad-Ratio-quad-Test"><a href="#square-quad-d’Alembert-quad-or-quad-Cauchy-quad-Ratio-quad-Test" class="headerlink" title="$$\square\quad d’Alembert\quad (or\quad Cauchy)\quad Ratio\quad Test$$"></a>$$\square\quad d’Alembert\quad (or\quad Cauchy)\quad Ratio\quad Test$$</h4><p>​	$$\frac{a_{n+1}}{a_n}~\leq r&lt;1 \Rightarrow$$ {$$a_n$$} is convergent.</p>
<p>​	$$\frac{a_{n+1}}{a_n}~\geq 1\Rightarrow$$  {$$a_n$$} is divergent.</p>
<p>​	$$\begin{equation}\underset{n\to\infty}{lim}~(\frac{a_{n+1}}{a_n})\left{\begin{array}{lr}&lt;1,\quad congvergent &amp;\&#x3D;1,\quad divergent &amp;\&gt;1,\quad indeterminate &amp;\end{array}\right.\end{equation}$$</p>
<p>​	At some crucial point , the test may fail. For example , $$a_n&#x3D;\frac{1}{n}$$ (harmonic series) :<br>$$<br>\frac{a_{n+1}}{a_n}<del>&#x3D;</del>\frac{n}{n+1}&lt;1<br>$$<br>​	but we cannot find r (&lt; 1) independent of n.</p>
<p>​	Since $$\underset{n\to\infty}{lim}\frac{a_{n+1}}{a_n}~&#x3D;1$$ , the test fails.</p>
<h4 id="square-quad-Cauchy-quad-or-quad-Maclaurin-quad-Integral-quad-Test"><a href="#square-quad-Cauchy-quad-or-quad-Maclaurin-quad-Integral-quad-Test" class="headerlink" title="$$\square\quad Cauchy\quad (or\quad Maclaurin)\quad Integral\quad Test$$"></a>$$\square\quad Cauchy\quad (or\quad Maclaurin)\quad Integral\quad Test$$</h4><p>​	Consider $$f(x)$$ a continuous , monotonic decreasing function , in which $$f(n)&#x3D;a_n$$.<br>$$<br>\int_{1}^{\infty}f(x)dx\leq \sum_{n&#x3D;1}^{\infty}~a_n \leq\int_{1}^{\infty}f(x)dx+a_1<br>$$<br>​	We have an equation , it writes ,<br>$$<br>\sum_{n&#x3D;N_1+1}^{N_2}f(n)&#x3D;\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}(x-[x])f’(x)dx<br>$$<br>​	proof :<br>$$<br>\begin{flalign}<br>RHS<br>&#x3D;&amp;\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}(x-[x])f’(x)dx\<br>&#x3D;&amp;\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}xf’(x)dx-\int_{N_1}^{N_2}[x]f(x)dx\<br>&#x3D;&amp;\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}xd(f(x))-\sum_{n&#x3D;N_1}^{N_2-1}n\int_{n}^{n+1}f’(x)dx\<br>&#x3D;&amp;\int_{N_1}^{N_2}f(x)dx+N_2f(N_2)-N_1f(N_1)-\int_{N_1}^{N_2}f(x)dx-\sum_{N_1}^{N_2-1}n(f(n+1)-f(n))\<br>&#x3D;&amp;N_2f(N_2)-N_1f(N_1)-\sum_{N_1}^{N_2-1}n(f(n+1)-f(n))\<br>&#x3D;&amp;N_2f(N_2)-N_1f(N_1)+\sum_{n&#x3D;N_1+1}^{N_2}f(n)+N_1f(N_1)-N_2f(N_2)\<br>&#x3D;&amp;\sum_{n&#x3D;N_1+1}^{N_2}f(n)<br>\end{flalign}<br>$$<br>​	Then $$RHS&#x3D;LHS$$.</p>
<p>​	$$Q.E.D\quad\blacksquare$$</p>
<p>​	Alternative of the equation :<br>$$<br>\sum_{n&#x3D;N_1+1}^{N_2}f(n)&#x3D;\int_{N_1}^{N_2}f(x)dx+\int_{N_1}^{N_2}(x-[x]-\frac{1}{2})dx+\frac{1}{2}~(f(N_2)-f(N_1))<br>$$<br>​	In this kind of equation , the second part in the right hand side is a function that oscillates about zero.</p>
<h4 id="square-quad-More-quad-Sensitive-quad-Tests"><a href="#square-quad-More-quad-Sensitive-quad-Tests" class="headerlink" title="$$\square\quad More\quad Sensitive\quad Tests$$"></a>$$\square\quad More\quad Sensitive\quad Tests$$</h4><h5 id="1-quad-Kummer-quad-Theorem"><a href="#1-quad-Kummer-quad-Theorem" class="headerlink" title="$$1.\quad Kummer\quad Theorem$$"></a>$$1.\quad Kummer\quad Theorem$$</h5><p>​	If $$\underset{n\to\infty}{lim}(a_n\frac{u_N}{u_{n+1}}-a_{n+1})\geq C&gt;0$$ , where $$C$$ is a constant , we have {$$u_n$$} is convergent if $$\sum_{n}a_n^{-1}$$ is convergent. <strong>And if $$\sum_{n}a_n^{-1}$$ is divergent , the more weak it diverges , the more powerful the theorem will be.</strong></p>
<p>​	If $$\underset{n\to\infty}{lim}(a_n\frac{u_N}{u_{n+1}}-a_{n+1})\leq 0$$ , we have {$$u_n$$} is divergent if $$\sum_{n}a_n^{-1}$$ is divergent.</p>
<p>​	proof :<br>$$<br>\begin{flalign}<br>u_{N+1}&amp;\leq(a_Nu_N-a_{N+1}u_{N+1})&#x2F;C\<br>u_{N}&amp;\leq(a_{N-1}u_{N-1}-a_{N}u_{N})&#x2F;C\<br>…&amp;\leq…\quad…\<br>\Rightarrow\sum_{i&#x3D;N+1}^{n}u_i&amp;&#x3D;(a_Nu_N-a_nu_n)&#x2F;C&lt;a_Nu_N&#x2F;C\<br>\Rightarrow\quad&amp;Convergent<br>\end{flalign}<br>$$</p>
<h5 id="2-quad-Gauss’s-quad-Test"><a href="#2-quad-Gauss’s-quad-Test" class="headerlink" title="$$2.\quad Gauss’s\quad Test$$"></a>$$2.\quad Gauss’s\quad Test$$</h5><p>​	For large n , $$\frac{u_n}{u_{n+1}}&#x3D;1+\frac{h}{n}+\frac{B(n)}{n^2}$$ , we can know that<br>$$<br>\begin{equation}\left{\begin{array}{lr}h&gt;1\quad\Rightarrow\quad convergent\h\leq1\quad\Rightarrow\quad divergent\end{array}\right.\end{equation}<br>$$</p>
<h4 id="square-quad-Alternating-quad-Series"><a href="#square-quad-Alternating-quad-Series" class="headerlink" title="$$\square\quad Alternating\quad Series$$"></a>$$\square\quad Alternating\quad Series$$</h4><p>​	For series of the form $$\sum_{n&#x3D;1}^{\infty}(-1)^{n+1}a_n$$ , $$a_n&gt;0$$ , we have Leibniz Criterion :</p>
<p>​	<strong>If $$a_n$$ monotonically decreases , and $$lim_{n\to\infty}a_n&#x3D;0$$ , then {$$a_n$$} converges.</strong></p>
<p>​	proof :<br>$$<br>\begin{flalign}<br>&amp;R_{2n}&#x3D;(a_{2n+1}-a_{2n+2})+(a_{2n+3}-a_{2n+4})+···&gt;0\<br>&amp;R_{2n}&#x3D;a_{2n+1}-(a_{2n+2}-a_{2n+3})-(a_{2n+4}-a_{2n+5})-···&lt;a_{2n+1}\<br>&amp;\Rightarrow\quad 0&lt;R_{2n}&lt;a_{2n+1}<br>\end{flalign}<br>$$<br>​	so when $$n\uparrow,R_{2n}\uparrow$$.</p>
<p>​	$$Q.E.D\quad \blacksquare$$</p>
<h4 id="square-quad-Absolute-quad-quad-Conditional-quad-Convergence"><a href="#square-quad-Absolute-quad-quad-Conditional-quad-Convergence" class="headerlink" title="$$\square\quad Absolute\quad &amp;\quad Conditional\quad Convergence$$"></a>$$\square\quad Absolute\quad &amp;\quad Conditional\quad Convergence$$</h4><p>​	Absolute convergence : the absolute value of its terms form a convergent series.</p>
<p>​	Conditional convergence : not the situation above.</p>
<h4 id="square-quad-Operation-quad-on-quad-Series"><a href="#square-quad-Operation-quad-on-quad-Series" class="headerlink" title="$$\square\quad Operation\quad on\quad Series$$"></a>$$\square\quad Operation\quad on\quad Series$$</h4><p>​	$$\bullet$$ If an infinite series is absolutely convergent , the series sum is independent of the order in which the terms are added.</p>
<p>​	$$\bullet$$ An absolutely convergent series may be added termwise to , or subtracted termwise from , or multiplied termwise with another absolutely convergent series , and the resulting series will also be absolutely convergent.</p>
<p>​	$$\bullet$$ The series (as a whole) may be multiplied with another absolutely convergent series. The limit of the product will be the product of the individual series limits. The product series , a double series , will also convergent absolutely.</p>
<h4 id="square-quad-Improvement-quad-of-quad-Convergence"><a href="#square-quad-Improvement-quad-of-quad-Convergence" class="headerlink" title="$$\square\quad Improvement\quad of\quad Convergence$$"></a>$$\square\quad Improvement\quad of\quad Convergence$$</h4><p>​	The rate of convergence : to form a linear combination of our slowly converging series and one or more series whose sum is known.</p>
<p>​	For the known series , the following collection is particularly useful :<br>$$<br>\alpha_1&#x3D;\sum_{n&#x3D;1}^{\infty}\frac{1}{n(n+1)}&#x3D;1\<br>\alpha_2&#x3D;\sum_{n&#x3D;1}^{\infty}\frac{1}{n(n+1)(n+2)}&#x3D;\frac{1}{4}\<br>\alpha_3&#x3D;\sum_{n&#x3D;1}^{\infty}\frac{1}{n(n+1)(n+2)(n+3)}&#x3D;\frac{1}{18}\<br>…\<br>\alpha_p&#x3D;\sum_{n&#x3D;1}^{\infty}\frac{1}{n(n+1)···(n+p)}&#x3D;\frac{1}{p·p!}<br>$$<br>​	The series we want to sum and one or more known series (multiplied by coefficient) are combined term by term. The coefficients in the linear combination are chosen to cancel the most slowly converging terms.</p>
<h4 id="square-quad-Rearrangement-quad-of-quad-Double-quad-Series"><a href="#square-quad-Rearrangement-quad-of-quad-Double-quad-Series" class="headerlink" title="$$\square\quad Rearrangement\quad of\quad Double\quad Series$$"></a>$$\square\quad Rearrangement\quad of\quad Double\quad Series$$</h4><p>​	For $$S&#x3D;\sum_{m&#x3D;0}^{\infty}\sum_{n&#x3D;0}^{\infty}a_{n,m}$$ ,<br>$$<br>\begin{equation}<br>rearrangement\quad of\quad S&#x3D;\left{<br>\begin{array}{lr}<br>\sum_{p&#x3D;0}^{\infty}\sum_{q&#x3D;0}^{p}a_{p-q,q}\<br>\sum_{q&#x3D;0}^{\infty}\sum_{p&#x3D;q}^{\infty}a_{p-q,q}\<br>\sum_{r&#x3D;0}^{\infty}\sum_{s&#x3D;0}^{[r&#x2F;2]}a_{s,r-2s}<br>\end{array}<br>\right.<br>\end{equation}<br>$$</p>
<h3 id="S1-2-quad-Series-quad-of-quad-Functions"><a href="#S1-2-quad-Series-quad-of-quad-Functions" class="headerlink" title="$$\S1.2\quad Series\quad of\quad Functions$$"></a>$$\S1.2\quad Series\quad of\quad Functions$$</h3><p>​	Let’s extend our concept of infinite series to include series of functions :</p>
<p>$$<br>s_n(x)&#x3D;&amp;u_1(x)+u_2(x)+···+u_n(x)\S(x)&#x3D;&amp;\sum_{n&#x3D;1}^{\infty}u_n(x)&#x3D;lim_{n\to\infty}s_n(x)<br>$$</p>
<h4 id="square-quad-Uniform-quad-Convergence"><a href="#square-quad-Uniform-quad-Convergence" class="headerlink" title="$$\square\quad Uniform\quad Convergence$$"></a>$$\square\quad Uniform\quad Convergence$$</h4><p>​	If for any small $$\epsilon&gt;1$$ , there exists a number $$N$$ , independent of $$x$$ in the interval [$$a,b$$]   (that is , $$a&lt;x&lt;b$$) such that ,<br>$$<br>|S(x)-s_n(x)|&lt;\epsilon , for\quad all\quad n\geq N<br>$$<br>​	Then the series is said to be <strong>uniformly convergent</strong>.</p>
<h4 id="square-quad-Weierstrass-quad-M-Majorant-quad-Test"><a href="#square-quad-Weierstrass-quad-M-Majorant-quad-Test" class="headerlink" title="$$\square\quad Weierstrass\quad M(Majorant)\quad Test$$"></a>$$\square\quad Weierstrass\quad M(Majorant)\quad Test$$</h4><p>​	If we can construct a series of numbers $$\sum_{i&#x3D;1}^{\infty}M_i$$ , in which $$M_i\geq|u_i(x)|$$ for all $$x$$ in the interval [$$a,b$$] , and $$\sum_{i&#x3D;1}^{\infty}M_i$$ is convergent , then our series $$u_i(x)$$ will be <strong>uniformly convergent</strong> in [$$a,b$$].</p>
<p>​	proof :</p>
<p>$$<br>&amp;\sum_{i&#x3D;n+1}^{\infty}M_i&lt;\epsilon,\quad\sum_{i&#x3D;n+1}^{\infty}M_i&gt;\sum_{i&#x3D;n+1}^{\infty}u_i(x)\&amp;\Rightarrow\sum_{i&#x3D;n+1}^{\infty}u_i(x)&lt;\epsilon\&amp;\Rightarrow|S(x)-s_n(x)|&#x3D;|\sum_{i&#x3D;n+1}^{\infty}u_i(x)|&lt;\epsilon&amp;<br>$$<br>​	<strong>Uniform convergence has nothing with absolute convergence.</strong> But M test can only establish for absolutely convergent series.</p>
<h4 id="square-quad-Abel’s-quad-Test"><a href="#square-quad-Abel’s-quad-Test" class="headerlink" title="$$\square\quad Abel’s\quad Test$$"></a>$$\square\quad Abel’s\quad Test$$</h4><p>​	A somewhat more delicate test for uniform convergence has been given by Abel. If $$u_n(x)$$ can be written in the uniform $$a_nf_n(x)$$ , and</p>
<ol>
<li>The $$a_n$$ form a convergent series , $$\sum_{n}a_n&#x3D;A$$.</li>
<li>For all $$x$$ in [$$a,b$$] the functions $$f_n(x)$$ are monotonically decreasing in $$n$$ , that is , $$f_{n+1}(x)\leq f_{n}(x)$$.</li>
<li>For all $$x$$ in [$$a,b$$] , all the $$f_n(x)$$ are bounded in the range $$0\leq f_n(x)\leq M$$ , where $$M$$ is independent of $$x$$.</li>
</ol>
<p>​	Then $$\sum_{n}u_n(x)$$ converges uniformly in [$$a,b$$]. This method is especially useful in analyzing the convergence of power series.</p>
<h4 id="square-quad-Properties-of-Uniformly-Convergent-Series"><a href="#square-quad-Properties-of-Uniformly-Convergent-Series" class="headerlink" title="$$\square\quad Properties,,of,,Uniformly,,Convergent,,Series$$"></a>$$\square\quad Properties,,of,,Uniformly,,Convergent,,Series$$</h4><p>​	If a series $$\sum_nu_n(x)$$ is uniformly convergent in [$$a,b$$] and the individual terms $$u_n(x)$$ are continuous ,</p>
<ol>
<li>The series sum $$S(x)&#x3D;\sum_{n&#x3D;1}^{\infty}u_n(x)$$ is also continuous ,</li>
<li>$$\int_{a}^{b}S(x)dx&#x3D;\sum_{n&#x3D;1}^{\infty}\int_{a}^{b} u_n(x)$$ ,</li>
<li>if the following additional conditions are also satisfied , then $$\sum_{n&#x3D;1}^{\infty}\frac{du_n(x)}{dx}$$ is uniformly convergent in       [$$a,b$$] : $$\frac{du_n(x)}{dx}$$ is continuous in [$$a,b$$].</li>
</ol>
<p>​	The first and second conditions are always right in physics , but the third is not because it is more restrictive.</p>
<h4 id="square-quad-Taylor’s-quad-Expansion"><a href="#square-quad-Taylor’s-quad-Expansion" class="headerlink" title="$$\square\quad Taylor’s\quad Expansion$$"></a>$$\square\quad Taylor’s\quad Expansion$$</h4><p>​	We assume that our function $$f(x)$$ has a continuous n-th derivative in the interval [$$a,b$$].</p>
<p>​	First , let’s intergrate this n-th derivative n times :<br>$$<br>\int_{a}^{x}f^{(n)}(x_1)dx_1&#x3D;f^{(n-1)}(x)-f^{(n-1)}(a)\<br>\int_{a}^{x}(\int_{a}^{x_2}f^{(n)}(x_1)dx_1)dx_2&#x3D;f^{(n-2)}(x)-f^{(n-2)}(a)-(x-a)f^{(n-1)}(a)\<br>\int_{a}^{x}(\int_{a}^{x_3}(\int_{a}^{x_2}f^{(n)}(x_1)dx_1)dx_2)dx_3&#x3D;\f^{(n-3)}(x)-f^{(n-3)}(a)-(x-a)f^{(n-2)}(a)-\frac{(x-a)^2}{2!}f^{(n-1)}(a)\<br>···<br>$$<br>​	Finally ， after integrating for the n-th time ,<br>$$<br>\int_{a}^{x}dx_{n}\int_{a}^{x_n}dx_{n-1}···\int_{a}^{x_{2}}dx_1·f^{(n)}(x)&#x3D;\<br>f(x)-f(a)-(x-a)f’(a)-\frac{(x-a)^2}{2!}f’’(a)-···-\frac{(x-a)^{n-1}}{(n-1)!}f^{(n-1)}(a)\<br>\Rightarrow f(x)&#x3D;f(a)+(x-a)f’(a)+\frac{(x-a)^2}{2!}f’’(a)+···+\frac{(x-a)^{n-1}}{(n-1)!}f^{(n-1)}(a)+R_n<br>$$<br>​	where the remainder , $$R_n$$ , is given by the n-fold integral ,<br>$$<br>R_n&#x3D;\int_{a}^{x}dx_{n}\int_{a}^{x_n}dx_{n-1}···\int_{a}^{x_{2}}dx_1·f^{(n)}(x)<br>$$<br>​	We may convert $$R_n$$ into a perhaps more pratical form by using the mean value theorem of integral calculus ,<br>$$<br>\int_{a}^{x}g(x)dx&#x3D;(x-a)g(\xi)\<br>\begin{flalign}<br>\Rightarrow R_n&amp;&#x3D;\int_{a}^{x}dx_{n}\int_{a}^{x_n}dx_{n-1}···\int_{a}^{x_{2}}dx_1·f^{(n)}(x)\<br>&amp;&#x3D;\frac{(x-a)^n}{n!}f^{(n)}(\xi)\<br>\end{flalign}<br>$$<br>​	Or applying Cauchy’s mean value theorem of integral calculus ,<br>$$<br>R_n&#x3D;\frac{(x-\xi)^{n-1}(x-a)}{(n-1)!}f^{(n)}(\xi)<br>$$<br>​	When you adjust n properly , $$R_n\to0$$. Then we have <strong>Taylor Expansion</strong> , which writes<br>$$<br>f(x)&#x3D;\sum_{n&#x3D;0}^{\infty}\frac{(x-a)^n}{n!}f^{(n)}(a)<br>$$</p>
<h4 id="square-quad-Power-quad-Series"><a href="#square-quad-Power-quad-Series" class="headerlink" title="$$\square\quad Power\quad Series$$"></a>$$\square\quad Power\quad Series$$</h4><p>​	When $$a&#x3D;0$$ , we have Maclaurin series ,<br>$$<br>f(x)&#x3D;f(0)+xf’(x)+\frac{x^2}{2!}f’’(0)+···&#x3D;\sum_{n&#x3D;0}^{\infty}\frac{x^n}{n!}f^{(n)}(0)<br>$$</p>
<h4 id="square-quad-Properties-quad-of-quad-Power-quad-Series"><a href="#square-quad-Properties-quad-of-quad-Power-quad-Series" class="headerlink" title="$$\square\quad Properties\quad of\quad Power\quad Series$$"></a>$$\square\quad Properties\quad of\quad Power\quad Series$$</h4><p>​	$$f(x)&#x3D;\sum_{n&#x3D;0}^{\infty}a_nx^n$$ , in which $$a_n$$ is independent of $$x$$. If $$lim_{n\to\infty}|\frac{a_{n+1}}{a_n}|&#x3D;R^{-1}$$ , then $$R$$ is the radius of convergence , and the series converges for $$x\in(-R,R)$$.</p>
<p>​	But the ratio &#x2F; root test fails at endpoints , $$x&#x3D;\pm R$$ needs special attention. In M test , the series is uniformly and absolutely convergent in ($$-R,R$$).</p>
<h4 id="square-quad-Uniqueness-quad-Theorem"><a href="#square-quad-Uniqueness-quad-Theorem" class="headerlink" title="$$\square\quad Uniqueness\quad Theorem$$"></a>$$\square\quad Uniqueness\quad Theorem$$</h4><p>​	<strong>The power-series representation is unique.</strong> Assume that<br>$$<br>\begin{flalign}<br>f(x)&amp;&#x3D;\sum_{n&#x3D;0}^{\infty}a_nx^n,\quad -R_a&lt;x&lt;R_a\<br>&amp;&#x3D;\sum_{n&#x3D;0}^{\infty}b_nx^n,\quad -R_b&lt;x&lt;R_b<br>\end{flalign}<br>$$<br>​	What we need to prove is that $$a_n&#x3D;b_n$$ , for all $$n$$.<br>$$<br>\sum_{n&#x3D;0}^{\infty}a_nx^n&#x3D;\sum_{n&#x3D;0}^{\infty}b_nx^n,\quad -R&lt;x&lt;R\<br>in\quad which\quad R\leq R_a,,,R_b<br>$$<br>​	When $$x&#x3D;0$$ , we have $$a_0&#x3D;b_0$$. Then differentiate the series ,<br>$$<br>\sum_{n&#x3D;0}^{\infty}na_nx^{n-1}&#x3D;\sum_{n&#x3D;0}^{\infty}nb_nx^{n-1},\quad -R&lt;x&lt;R\<br>in\quad which\quad R\leq R_a,,,R_b<br>$$<br>​	When $$x&#x3D;0$$ , we have $$a_1&#x3D;b_1$$. ··· ···</p>
<p>​	Repeating the process , we will get $$a_n&#x3D;b_n$$.</p>
<p>​	$$Q.E.D\quad \blacksquare$$</p>
<p>​	This theorem will be a crucial point in our study of differential equations , in which we develop power series solutions (For instance , in theoretical physics , there’s perturbation theory in quantum mechanics).</p>
<h4 id="square-quad-Indeterminate-quad-Forms"><a href="#square-quad-Indeterminate-quad-Forms" class="headerlink" title="$$\square\quad Indeterminate\quad Forms$$"></a>$$\square\quad Indeterminate\quad Forms$$</h4><p>​	You can use the power-series representation of functions to prove $$L’H \hat{o} pital’s,,,Rule$$ :<br>$$<br>\underset{x\to x_0}{lim}\frac{f(x)}{g(x)}&#x3D;\underset{x\to x_0}{lim}\frac{f’(x)}{g’(x)}<br>$$<br>​	(See exercise 1.2.12)</p>
<h4 id="square-quad-Inversion-quad-of-quad-Power-quad-Series"><a href="#square-quad-Inversion-quad-of-quad-Power-quad-Series" class="headerlink" title="$$\square\quad Inversion\quad of\quad Power\quad Series$$"></a>$$\square\quad Inversion\quad of\quad Power\quad Series$$</h4><p>​	Consider that $$y-y_0&#x3D;\sum_{n&#x3D;1}^{\infty}a_n(x-x_0)^n$$ , if we want to know $$x-x_0&#x3D;\sum_{n&#x3D;1}^{\infty}b_n(y-y_0)^n$$ ,  we need to equate coefficients of $$(x-x_0)^n$$ on both sides of the given equation.<br>$$<br>b_1&#x3D;\frac{1}{a_1}\<br>b_2&#x3D;-\frac{a_2}{a_1^3}\<br>b_3&#x3D;\frac{2a_2^2}{a_1^5}-\frac{a_3}{a_1^4}\<br>b_4&#x3D;\frac{5a_2a_3}{a_1^6}-\frac{a_4}{a_1^5}-\frac{5a_2^3}{a_1^7}\<br>···<br>$$</p>
<h3 id="S1-3-quad-Binomial-quad-Theorem"><a href="#S1-3-quad-Binomial-quad-Theorem" class="headerlink" title="$$\S1.3\quad Binomial\quad Theorem$$"></a>$$\S1.3\quad Binomial\quad Theorem$$</h3><p>​	Binomial series is a extremely significant application of the Maclaurin series. Let $$f(x)&#x3D;(1+x)^m$$ , in which $$m\in\Re$$. Then ,<br>$$<br>(1+x)^m&#x3D;1+mx+\frac{m(m-1)}{2!}x^2+···+R_n<br>$$<br>​	For this function , the remainder is<br>$$<br>R_n&#x3D;\frac{x^n}{n!}(1+\xi)^{m-n}m(m-1)···(m-n+1)<br>$$<br>​	with $$\xi\in(0,x)$$.</p>
<p>​	When $$x&gt;0$$ , for $$n&gt;m$$ , $$(1+\xi)^{m-n}$$ is a maximum for $$\xi&gt;0$$. So for $$x&gt;0$$ , $$|R_n|\leq\frac{x^n}{n!}|m(m-1)···(m-n+1)|$$ , with $$\underset{n\to\infty}{lim}R_n&#x3D;0$$ , when $$0\leq x&lt;1$$. </p>
<p>​	Because the radius of convergence of a power series is the same for positive and negative $$x$$ , the binomial series converges for $$-1&lt;x&lt;1$$. The endpoints cannot be determined.</p>
<p>​	<strong>Binomial Expansion :</strong><br>$$<br>(1+x)^m&#x3D;1+mx+\frac{m(m-1)}{2!}x^2+\frac{m(m-1)(m-2)}{3!}x^3+···<br>$$<br>​	If $$m$$ is a nonnegative integer , $$R_n$$ for $$n&gt;m$$ vanishes for all $$x$$ , corresponding to the fact that under those conditions $$(1+x)^m$$ is a finite sum.</p>
<p>​	<strong>Binomial Coefficients :</strong><br>$$<br>\begin{equation}<br>\left\lgroup<br>\begin{array}{lr}<br>m\<br>n<br>\end{array}<br>\right\rgroup&#x3D;\frac{m(m-1)···(m-n+1)}{n!}<br>\end{equation}<br>$$</p>
<p>$$<br>\begin{equation}<br>(1+x)^m&#x3D;\sum_{n&#x3D;0}^{\infty}\left\lgroup<br>\begin{array}{lr}<br>m\<br>n<br>\end{array}<br>\right\rgroup x^n<br>\end{equation}<br>$$</p>
<p>​	In which , when $$n&#x3D;0$$ , $$\begin{equation}\left\lgroup\begin{array}{lr}m\0\end{array}\right\rgroup &#x3D;1\end{equation}$$.</p>
<p>​	1. When $$m$$ is a positive integer , $$\begin{equation}\left\lgroup\begin{array}{lr}m\n\end{array}\right\rgroup &#x3D;\frac{m!}{n!(m-n)!}\end{equation}$$. That is $$C_m^n&#x3D;\begin{equation}\left\lgroup\begin{array}{lr}m\n\end{array}\right\rgroup\end{equation}$$.</p>
<p>​	2. For negative integer $$m$$ , set $$m&#x3D;-p$$ , there is<br>$$<br>\begin{equation}<br>\left\lgroup<br>\begin{array}{lr}<br>-p\<br>n<br>\end{array}<br>\right\rgroup&#x3D;(-1)^n\frac{p(p+1)···(p+n-1)}{n!}&#x3D;(-1)^n\frac{(p+n-1)!}{n!(p-1)!}<br>\end{equation}<br>$$</p>
<p>​	3. For nonintegral $$m$$ , it is convenient to use the <strong>Pochhammer Symbol</strong> , defined for general a and nonnegative integer $$n$$ , as<br>$$<br>(a)_0&#x3D;1,,\quad(a)_1&#x3D;a,,\quad(a)<em>2&#x3D;a(a+1),,\quad···\<br>(a)</em>{n+1}&#x3D;a(a+1)···(a+n)\<br>\begin{equation}<br>\left\lgroup<br>\begin{array}{lr}<br>m\<br>n<br>\end{array}\right\rgroup&#x3D;\frac{(m-n+1)_n}{n!}<br>\end{equation}<br>$$</p>
<p>​	For addition , $$0!!&#x3D;(-1)!!&#x3D;1$$ , because $$(2n)!!&#x3D;2^nn!$$ , and $$(2n-1)!!&#x3D;\frac{(2n)!!}{2^nn!}$$.</p>
<h4 id="square-quad-Generalized-quad-Binomial-quad-Expansion"><a href="#square-quad-Generalized-quad-Binomial-quad-Expansion" class="headerlink" title="$$\square\quad Generalized\quad Binomial\quad Expansion$$"></a>$$\square\quad Generalized\quad Binomial\quad Expansion$$</h4><p>​	1. For positive integer $$n$$ , to polynomials ,<br>$$<br>(a_1+a_2+···+a_m)^n&#x3D;\sum\frac{n!}{n_1!n_2!···n_m!}a_1^{n_1}a_2^{n_2}···a_m^{n_m}<br>$$</p>
<p>​	In which $$\sum_{i&#x3D;1}^mn_i&#x3D;n$$.</p>
<ol start="2">
<li>$$<br>\begin{equation}<br>(\frac{d}{dx})^n(u(x)v(x))&#x3D;\sum_{i&#x3D;0}^{n}<br>\left\lgroup<br>\begin{array}{lr}<br>n\i<br>\end{array}<br>\right\rgroup(\frac{d^iu(x)}{dx^i})(\frac{d^{n-i}v(x)}{dx^{n-i}})<br>\end{equation}<br>$$</li>
</ol>
<h3 id="S1-4-quad-Mathematical-quad-Induction"><a href="#S1-4-quad-Mathematical-quad-Induction" class="headerlink" title="$$\S1.4\quad Mathematical\quad Induction$$"></a>$$\S1.4\quad Mathematical\quad Induction$$</h3><p>​	If a relation is valid for an arbitrary value of some index $$n$$ , then it is also valid if $$n$$ is replaced by $$(n+1)$$.</p>
<h3 id="S1-5-quad-Operations-on-Series-Expansions-of-Functions"><a href="#S1-5-quad-Operations-on-Series-Expansions-of-Functions" class="headerlink" title="$$\S1.5\quad Operations,,on,,Series,,Expansions,,of,,Functions$$"></a>$$\S1.5\quad Operations,,on,,Series,,Expansions,,of,,Functions$$</h3><p>​	For example ,<br>$$<br>\begin{flalign}<br>\frac{1}{1+x}&#x3D;&amp;1-x+x^2-x^3+···\<br>\overset{integral}{\Longrightarrow}ln(1+x)&#x3D;&amp;x-\frac{1}{2}x^2+\frac{1}{3}x^3-\frac{1}{4}x^4+···<br>\end{flalign}<br>$$</p>
<h3 id="S1-6-quad-Some-quad-Important-quad-Series"><a href="#S1-6-quad-Some-quad-Important-quad-Series" class="headerlink" title="$$\S1.6\quad Some\quad Important\quad Series$$"></a>$$\S1.6\quad Some\quad Important\quad Series$$</h3><p>$$<br>\begin{flalign}<br>e^x&#x3D;&amp;\sum_{n&#x3D;0}^{\infty}\frac{x^n}{n!}&#x3D;1+x+\frac{1}{2}x^2+···\<br>sin(x)&#x3D;&amp;\sum_{n&#x3D;0}^{\infty}\frac{(-1)^nx^{2n+1}}{(2n+1)!}&#x3D;x-\frac{1}{6}x^3+···\<br>sinh(x)&#x3D;&amp;\sum_{n&#x3D;0}^{\infty}\frac{x^{2n+1}}{(2n+1)!}&#x3D;x+\frac{1}{6}x^3+···\<br>cos(x)&#x3D;&amp;\sum_{n&#x3D;0}^{\infty}\frac{(-1)^nx^{2n}}{(2n)!}&#x3D;1-\frac{1}{2}x^2+···\<br>cosh(x)&#x3D;&amp;\sum_{n&#x3D;0}^{\infty}\frac{x^{2n}}{(2n)!}&#x3D;1+\frac{1}{2}x^2+···\<br>\frac{1}{1-x}&#x3D;&amp;\sum_{n&#x3D;0}^{\infty}x^n&#x3D;1+x+···\<br>ln(1+x)&#x3D;&amp;\sum_{n&#x3D;0}^{\infty}\frac{(-1)^{n-1}x^n}{n}&#x3D;x-\frac{1}{2}x^2+···\<br>\end{flalign}<br>$$</p>
<p>$$<br>\begin{equation}<br>(1+x)^p&#x3D;\sum_{n&#x3D;0}^{\infty}\left\lgroup<br>\begin{array}{lr}<br>p\<br>n<br>\end{array}<br>\right\rgroup x^n&#x3D;\sum_{n&#x3D;0}^{\infty}\frac{(p-n+1)_n}{n!}x^n&#x3D;1+\frac{p}{1!}x+\frac{p(p-1)}{2!}x^2+\cdots<br>\end{equation}<br>$$</p>
<h3 id="S1-7-quad-Vectors"><a href="#S1-7-quad-Vectors" class="headerlink" title="$$\S1.7\quad Vectors$$"></a>$$\S1.7\quad Vectors$$</h3><p>​	Scalar is defined as quantity that has algebraic magnitude only.</p>
<p>​	Vector is defined as quantity that has magnitude and direction. Vectors defined over a region are called vector fields.</p>
<h4 id="square-quad-Basic-quad-Properties"><a href="#square-quad-Basic-quad-Properties" class="headerlink" title="$$\square\quad Basic\quad Properties$$"></a>$$\square\quad Basic\quad Properties$$</h4><p>​	Let’s just skip this part ···</p>
<h4 id="square-quad-Dot-Scalar-quad-Product"><a href="#square-quad-Dot-Scalar-quad-Product" class="headerlink" title="$$\square\quad Dot(Scalar)\quad Product$$"></a>$$\square\quad Dot(Scalar)\quad Product$$</h4><p>​	Algebraic formula :  $$\vec{A}\cdot\vec{B}&#x3D;\sum_iA_iB_i&#x3D;\sum_iB_iA_i&#x3D;\vec{B}\cdot\vec{A}$$</p>
<p>​	( That is , if $$\vec{C}&#x3D;\vec{A}+\vec{B}$$ , then $$\vec{A}\cdot\vec{B}&#x3D;\frac{1}{2}(|\vec{C}|^2-|\vec{A}|^2-|\vec{B}|^2)$$ )</p>
<p>​	Geometric formula : $$\vec{A}\cdot\vec{B}&#x3D;|\vec{A}||\vec{B}|cos\theta$$ , in which $$\theta&#x3D;&lt;\vec{A},\vec{B}&gt;$$.</p>
<p>​	The projection of $$\vec{A}$$ in direction of $$\vec{B}$$ : $$\vec{A_b}&#x3D;(\vec{A}\cdot\frac{\vec{B}}{|\vec{B}|})\frac{\vec{B}}{|\vec{B}|}$$</p>
<p>​	Schwarz inequality : $$|\vec{A}\cdot\vec{B}|\leq|\vec{A}||\vec{B}|$$</p>
<h4 id="square-quad-Orthogonality"><a href="#square-quad-Orthogonality" class="headerlink" title="$$\square\quad Orthogonality$$"></a>$$\square\quad Orthogonality$$</h4><p>​	If $$\vec{A}、\vec{B}\neq0$$ , then<br>$$<br>\vec{A}\cdot\vec{B}&#x3D;0\iff\vec{A}、\vec{B},,,,are,,orthogonal.<br>$$</p>
<h3 id="S1-8-quad-Complex-quad-Numbers-quad-quad-Functions"><a href="#S1-8-quad-Complex-quad-Numbers-quad-quad-Functions" class="headerlink" title="$$\S1.8\quad Complex\quad Numbers\quad &amp;\quad Functions$$"></a>$$\S1.8\quad Complex\quad Numbers\quad &amp;\quad Functions$$</h3><h4 id="square-quad-Basic-quad-Properties-1"><a href="#square-quad-Basic-quad-Properties-1" class="headerlink" title="$$\square\quad Basic\quad Properties$$"></a>$$\square\quad Basic\quad Properties$$</h4><p>​	A complex number is an ordered pair of two real variables , $$z&#x3D;(x,y)$$ (the order is significant) , in which $$i&#x3D;(0,1)$$ is the imaginary unit.</p>
<p>​	Addition : $$z_1+z_2&#x3D;(x_1,y_1)+(x_2,y_2)&#x3D;(x_1+x_2,y_1+y_2)$$</p>
<p>​	Multiplication : $$z_1\cdot z_2&#x3D;(x_1,y_1)\cdot(x_2,y_2)&#x3D;(x_1x_2-y_1y_2,x_1y_2+x_2y_1)$$<br>$$<br>\begin{flalign}<br>\Rightarrow&amp; i^2&#x3D;(0,1)\cdot(0,1)&#x3D;(-1,0)&#x3D;-1\<br>\Rightarrow&amp; (x_1+iy_1)\cdot(x_2+iy_2)&#x3D;(x_1x_2-y_1y_2)+i(x_1y_2+x_2y_1)<br>\end{flalign}<br>$$<br>​	For historical reasons , $$i$$ and its multiples are known as imaginary numbers.</p>
<p>​	The space of complex numbers , sometimes denoted $$\Z$$ , by mathematicians , has the following formal properties :</p>
<p>​	1. It is closed under addition and multiplication , meaning that if two complex numbers are added or multiplied , the result is also a complex number.</p>
<p>​	2.It has a unique zero number , which when added to any complex number leaves it unchanged and which , when multiplied with any complex number yields zero.</p>
<p>​	3.It has a unique unit number $$1$$ , which when multiplied with any complex number leaves it unchanged.</p>
<p>​	4.Every complex number $$z$$ has an inverse under addition (known as $$-z$$) , and every nonzero $$z$$ has an inverse under multiplication , denoted $$z^{-1}$$ or $$1&#x2F;z$$.</p>
<p>​	5.It is closed under exponentiation : if $$u$$ and $$v$$ are complex numbers , the $$u^v$$ is also a complex number.</p>
<p>​	Complex conjugation : $$z&#x3D;x+iy\Longleftrightarrow z^*&#x3D;x-iy$$<br>$$<br>\begin{flalign}<br>\Rightarrow&amp; z\cdot z^*&#x3D;x^2+y^2\<br>\Rightarrow&amp; |z|&#x3D;\sqrt{z\cdot z^*}<br>\end{flalign}<br>$$<br>​	Division :<br>$$<br>\frac{z’}{z}&#x3D;\frac{z’\cdot z^*}{z\cdot z^*}&#x3D;\frac{(x’+iy’)(x-iy)}{x^2+y^2}&#x3D;\frac{xx’+yy’}{x^2+y^2}+i\frac{xy’-x’y}{x^2+y^2}<br>$$</p>
<h4 id="square-quad-Functions-quad-in-quad-the-quad-Complex-quad-Domain"><a href="#square-quad-Functions-quad-in-quad-the-quad-Complex-quad-Domain" class="headerlink" title="$$\square\quad Functions\quad in\quad the\quad Complex\quad Domain$$"></a>$$\square\quad Functions\quad in\quad the\quad Complex\quad Domain$$</h4><p>​	Among other things , that if a function is represented by a power series , we should , within the region of convergence of the power series , be able to use such series with complex values of the expansion variable. This is called the permanence of the algebraic form.<br>$$<br>e^z&#x3D;1+z+\frac{1}{2!}z^2+\cdots\<br>\begin{flalign}<br>e^{iz}&#x3D;&amp;1+(iz)+\frac{1}{2!}(iz)^2+\cdots\<br>&#x3D;&amp;(1-\frac{1}{2!}z^2+\cdots)+i(z-\frac{1}{3!}z^3+\cdots)\<br>&#x3D;&amp;cos(z)+isin(z)<br>\end{flalign}<br>$$<br>​	which is called <strong>Euler equation</strong>.</p>
<p>​	when $$z&#x3D;x+iy$$ , then $$f(z)&#x3D;u(x,y)+iv(x,y)$$ has real part $$\mathscr{Re}(f(z))&#x3D;u(x,y)$$ and imaginary part $$\mathscr{Im}(f(z))&#x3D;v(x,y)$$.</p>
<h4 id="square-quad-Polar-quad-Representation"><a href="#square-quad-Polar-quad-Representation" class="headerlink" title="$$\square\quad Polar\quad Representation$$"></a>$$\square\quad Polar\quad Representation$$</h4><p>​	Skip that $$\cdots$$ </p>
<p>​	$$z&#x3D;re^{i\theta}$$ , $$r$$ is called modulus , $$\theta$$ is called argument or phase. Since additon on an Argand diagram is analogous to $$2-D$$ vector addition , it can be seen that<br>$$<br>||z|-|z’||\leq|z\pm z’|\leq|z|+|z’|<br>$$<br>​	Remember , $$w(z)$$ is a mapping from $$xy$$ plane to $$uv$$ plane.</p>
<h4 id="square-quad-Complex-quad-Numbers-quad-of-quad-Unit-quad-Magnitude"><a href="#square-quad-Complex-quad-Numbers-quad-of-quad-Unit-quad-Magnitude" class="headerlink" title="$$\square\quad Complex\quad Numbers\quad of\quad Unit\quad Magnitude$$"></a>$$\square\quad Complex\quad Numbers\quad of\quad Unit\quad Magnitude$$</h4><p>​	They are on the unit circle.</p>
<h4 id="square-quad-Circular-quad-quad-Hyperbolic-quad-Functions"><a href="#square-quad-Circular-quad-quad-Hyperbolic-quad-Functions" class="headerlink" title="$$\square\quad Circular\quad &amp;\quad Hyperbolic\quad Functions$$"></a>$$\square\quad Circular\quad &amp;\quad Hyperbolic\quad Functions$$</h4><p>$$<br>\begin{flalign}<br>cos(\theta)&#x3D;\frac{e^{i\theta}+e^{-i\theta}}{2},&amp;,\qquad sin(\theta)&#x3D;\frac{e^{i\theta}-e^{-i\theta}}{2}\<br>cosh(\theta)&#x3D;\frac{e^{\theta}+e^{-\theta}}{2},&amp;,\qquad sinh(\theta)&#x3D;\frac{e^{\theta}-e^{-\theta}}{2}\\<br>\Longrightarrow\qquad cosh(iz)&#x3D;cos(z),&amp;,\qquad sinh(iz)&#x3D;isin(z)\\<br>cos(n\theta)+isin(n\theta)&amp;&#x3D;(cos(\theta)+isin(\theta))^n<br>\end{flalign}<br>$$</p>
<p>$$<br>\begin{flalign}<br>e^{iz}&#x3D;isin(z)&amp;+\sqrt{1-sin^2(z)}\<br>\Longrightarrow\qquad arcsin(z)&#x3D;&amp;-iln(iz+\sqrt{1-z^2})\<br>arctan(z)&#x3D;&amp;\frac{1}{2}iln(\frac{1-iz}{1+iz})\<br>arcsinh(z)&#x3D;&amp;ln(z+\sqrt{1+z^2})\<br>arctanh(z)&#x3D;&amp;\frac{1}{2}ln(\frac{1+z}{1-z})<br>\end{flalign}<br>$$</p>
<h4 id="square-quad-Power-quad-quad-Root"><a href="#square-quad-Power-quad-quad-Root" class="headerlink" title="$$\square\quad Power\quad &amp;\quad Root$$"></a>$$\square\quad Power\quad &amp;\quad Root$$</h4><p>​	The polar form is very convenient for expressing powers and roots of complex numbers. Consider when $$z&#x3D;re^{i\varphi}$$ , then<br>$$<br>z^n&#x3D;r^ne^{in\varphi}\<br>z^{1&#x2F;n}&#x3D;r^{1&#x2F;n}e^{i(\varphi+2m\pi)&#x2F;n}\<br>(m\in\Z)<br>$$<br>​	Actually , $$1&#x2F;n$$ root has $$n$$ different values.</p>
<h4 id="square-quad-Logarithm"><a href="#square-quad-Logarithm" class="headerlink" title="$$\square\quad Logarithm$$"></a>$$\square\quad Logarithm$$</h4><p>$$<br>ln(z)&#x3D;ln(re^{i\theta})&#x3D;ln(r)+i(\theta+2n\pi)\<br>(n\in\Z)<br>$$</p>
<p>​	$$\Longrightarrow$$ $$ln(z)$$ has infinite number of values.</p>
<h3 id="S1-9-quad-Derivatives-quad-quad-Extrema"><a href="#S1-9-quad-Derivatives-quad-quad-Extrema" class="headerlink" title="$$\S1.9\quad Derivatives\quad &amp;\quad Extrema$$"></a>$$\S1.9\quad Derivatives\quad &amp;\quad Extrema$$</h3><p>​	Definition of derivative :<br>$$<br>\frac{df(x)}{dx}|_x&#x3D;\underset{\epsilon\to0}{lim}\frac{f(x+\epsilon)-f(x)}{\epsilon}<br>$$<br>​	Variation $$&amp;$$ differential : $$df&#x3D;\frac{df}{dx}dx$$</p>
<p>​	When $$f(x,y,z)$$ , we have $$df&#x3D;\frac{\partial f}{\partial x}dx+\frac{\partial f}{\partial y}dy+\frac{\partial f}{\partial z}dz$$ , in which $$\frac{\partial f}{\partial x}$$ is called partial derivatives.</p>
<p>​	Cross derivatives : $$\frac{\partial^2 f}{\partial x\partial y}&#x3D;\frac{\partial^2 f}{\partial y\partial x}$$</p>
<p>​	1.The chain rule :<br>$$<br>\frac{df}{ds}&#x3D;\frac{\partial f}{\partial x}\frac{dx}{ds}+\frac{\partial f}{\partial y}\frac{dy}{ds}+\frac{\partial f}{\partial z}\frac{dz}{ds}<br>$$<br>​	2.Consider $$f&#x3D;f(x,y)$$ , then :<br>$$<br>(\frac{\partial f}{\partial x})_y(\frac{\partial x}{\partial y})_f(\frac{\partial y}{\partial f})_x&#x3D;-1<br>$$<br>​	In Lagrangian mechanics , we often encounter formulas such as<br>$$<br>\frac{d}{dt}L(x,\dot{x},t)&#x3D;\frac{\partial L}{\partial x}\dot{x}+\frac{\partial L}{\partial \dot{x}}\ddot{x}+\frac{\partial L}{\partial t}<br>$$<br>​	In which we need to distinguish between $$\frac{d}{dt}$$ and $$\frac{\partial}{\partial t}$$.</p>
<h4 id="square-quad-Stationary-quad-Points"><a href="#square-quad-Stationary-quad-Points" class="headerlink" title="$$\square\quad Stationary\quad Points$$"></a>$$\square\quad Stationary\quad Points$$</h4><p>​	If we want to know how a function $$f$$ changes if we move in various directions in the space of the independent variables , we can use<br>$$<br>\frac{df}{ds}&#x3D;\frac{\partial f}{\partial x}\frac{dx}{ds}+\frac{\partial f}{\partial y}\frac{dy}{ds}+\frac{\partial f}{\partial z}\frac{dz}{ds}<br>$$<br>​	In which the direction is given by $$\frac{dx_i}{ds}$$.</p>
<p>​	It is  often to find the minimum of a function $$f$$ of $$n$$ variables $$x_i$$ , $$i&#x3D;1,2,\cdots,n$$ , and a necessary but not sufficient condition on its position is that $$\frac{df}{ds}&#x3D;0$$ , for $$ds$$ in any direction. And this equals to $$\frac{\partial f}{\partial x_i}&#x3D;0$$ , $$i&#x3D;1,2,\cdots,n$$.</p>
<p>​	All points that satisfies the formula above are termed <strong>stationary</strong> :<br>$$<br>\begin{equation}<br>\left{<br>\begin{array}{lr}<br>\frac{d^2f}{ds^2}&gt;0\Longrightarrow minimum\<br>\frac{d^2f}{ds^2}&lt;0\Longrightarrow maximum\<br>else\Longrightarrow saddle<br>\end{array}<br>\right.<br>\end{equation}<br>$$</p>
<h3 id="S1-10-quad-Evaluation-quad-of-quad-Integrals"><a href="#S1-10-quad-Evaluation-quad-of-quad-Integrals" class="headerlink" title="$$\S1.10\quad Evaluation\quad of\quad Integrals$$"></a>$$\S1.10\quad Evaluation\quad of\quad Integrals$$</h3><p>​	<strong>$$\star\star\star$$ Proficiency in the evaluation of integrals involves a mixture of experience , skill in pattern recognition , and a few tricks. $$\star\star\star$$</strong></p>
<h4 id="square-quad-Integration-quad-by-quad-Parts"><a href="#square-quad-Integration-quad-by-quad-Parts" class="headerlink" title="$$\square\quad Integration\quad by\quad Parts$$"></a>$$\square\quad Integration\quad by\quad Parts$$</h4><p>​	Legendre Transformation :<br>$$<br>\begin{flalign}<br>d(uv)&#x3D;&amp;,udv+vdu\<br>\Longrightarrow udv&#x3D;&amp;,d(uv)-vdu\<br>\Longrightarrow \int_a^budv&#x3D;&amp;,uv|_a^b-\int_a^bvdu<br>\end{flalign}<br>$$</p>
<h4 id="square-quad-Special-quad-Functions"><a href="#square-quad-Special-quad-Functions" class="headerlink" title="$$\square\quad Special\quad Functions$$"></a>$$\square\quad Special\quad Functions$$</h4><table>
<thead>
<tr>
<th align="center">Functions</th>
<th align="center">Definitions</th>
<th align="center">Addition</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Gamma Function</td>
<td align="center">$$\Gamma(x)&#x3D;\int_0^{\infty}t^{x-1}e^{-t}dt$$</td>
<td align="center">See Chapter 13.</td>
</tr>
<tr>
<td align="center">Factorial ($$n$$ integral)</td>
<td align="center">$$n!&#x3D;\Gamma(n+1)$$</td>
<td align="center">&#x2F;</td>
</tr>
<tr>
<td align="center">Riemann Zeta Function</td>
<td align="center">$$\zeta(x)&#x3D;\frac{1}{\Gamma(x)}\int_0^\infty\frac{t^{x-1}dt}{e^t-1}$$</td>
<td align="center">See Chapter 1.$$&amp;$$12.</td>
</tr>
<tr>
<td align="center">Exponential Integrals</td>
<td align="center">$$E_n(x)&#x3D;\int_1^\infty t^{-n}e^{-xt}dt$$</td>
<td align="center">$$&#x3D;\int_x^\infty t^{-n}e^{-t}dt$$</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">$$Ei(x)&#x3D;\int_{-\infty}^{x}t^{-1}e^{-t}dt$$</td>
<td align="center">$$E_1(x)&#x3D;-Ei(-x)$$</td>
</tr>
<tr>
<td align="center">Sine Integral</td>
<td align="center">$$Si(x)&#x3D;-\int_x^{\infty}\frac{sin(t)}{t}dt$$</td>
<td align="center">&#x2F;</td>
</tr>
<tr>
<td align="center">Cosine Integral</td>
<td align="center">$$Ci(x)&#x3D;-\int_x^{\infty}\frac{cos(t)}{t}dt$$</td>
<td align="center">&#x2F;</td>
</tr>
<tr>
<td align="center">Error Functions</td>
<td align="center">$$erf(x)&#x3D;\frac{2}{\sqrt{\pi}}\int_0^xe^{-x^2}dt$$</td>
<td align="center">$$erf(\infty)&#x3D;1$$</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">$$erfc(x)&#x3D;\frac{2}{\sqrt{\pi}}\int_x^\infty e^{-x^2}dt$$</td>
<td align="center">$$erfc(x)&#x3D;1-erf(x)$$</td>
</tr>
<tr>
<td align="center">Dilogarithm</td>
<td align="center">$$Li_2(x)&#x3D;-\int_0^x\frac{ln(1-t)}{t}dt$$</td>
<td align="center">&#x2F;</td>
</tr>
</tbody></table>
<h4 id="square-quad-Other-quad-Methods"><a href="#square-quad-Other-quad-Methods" class="headerlink" title="$$\square\quad Other\quad Methods$$"></a>$$\square\quad Other\quad Methods$$</h4><p>​	An extremely powerful method for the evaluation of difinite integrals is that of contour integration in the complex plane. But this method will be presented in Chapter11. and not be dicussed here.</p>
<p>​	1.Integrals can often be evaluated by methods that involve integration or differentiation with respect to parameters , thereby obtaining relations between known integrals and those whose values are being sought.</p>
<p>​	2.Many integrals can be evaluated by first converting them into infinite series , then manipulating the resulting series , and finally either evaluating the series or recognizing it as a special function.</p>
<p>​	3.Simply using complex numbers aids in the evaluation of some integrals.</p>
<p>​	4.Recursion is useful in obtaining formulas for a set of related integrals.</p>
<h4 id="square-quad-Multiple-quad-Integrals"><a href="#square-quad-Multiple-quad-Integrals" class="headerlink" title="$$\square\quad Multiple\quad Integrals$$"></a>$$\square\quad Multiple\quad Integrals$$</h4><p>$$<br>\begin{flalign}<br>&amp;\iint f(x,y)dxdy\\<br>or\qquad &amp;\int_{x_1}^{x_2}dx\int_{y_1(x)}^{y_2(x)}dy\cdot f(x,y)\\<br>or\qquad &amp;\int_S f(x,y)dA<br>\end{flalign}<br>$$</p>
<p>​	In addition to the techniques available for integration in a single variable , multiple integrals provide further opportunities for evaluation based on changes in the order of integration and in the coordinate system used in the integral.</p>
<p>​	A significant change in the form of the $$2-D$$ or $$3-D$$ integrals can sometimes be accomplished by changing between Cartesian and polar coordinate systems.</p>
<h4 id="square-quad-Remarks-Changes-of-Integration-Variables"><a href="#square-quad-Remarks-Changes-of-Integration-Variables" class="headerlink" title="$$\square\quad Remarks,:,Changes,of,Integration,Variables$$"></a>$$\square\quad Remarks,:,Changes,of,Integration,Variables$$</h4><p>​	In a $$1-D$$ integration , a change in the integration variable from , say , $$x$$ to $$y(x)$$ involves two adjustments :</p>
<p>​	1.$$dx\longrightarrow(\frac{dx}{dy})dy$$</p>
<p>​	2.$$x_1,x_2\longrightarrow y(x_1),y(x_2)$$</p>
<p>​	If $$y(x)$$ and $$x(y)$$ is not single-valued , the process becomes more complicated , and we will not discuss it here.</p>
<p>​	For multiple integrals , we use <strong>Jacobian</strong>. For $$dxdy\longrightarrow Jdudv$$ , $$J&#x3D;\frac{\partial(x,y)}{\partial(u,v)}$$.</p>
<p>​	The computation of Jacobian will be discussed in Section4.4. Here , remember to determinate the transformed region.</p>
<h3 id="S1-11-quad-Dirac-quad-Delta-quad-Function"><a href="#S1-11-quad-Dirac-quad-Delta-quad-Function" class="headerlink" title="$$\S1.11\quad Dirac\quad Delta\quad Function$$"></a>$$\S1.11\quad Dirac\quad Delta\quad Function$$</h3><p>​	Definition :<br>$$<br>\delta(x)&#x3D;0,,,x\neq0\<br>f(0)&#x3D;\int_a^bf(x)\delta(x)dx,,,,,(a&lt;0&lt;b)\<br>\int_{-\infty}^{\infty}\delta(x)dx&#x3D;1<br>$$<br>​	<strong>No such function exists , (in the usual sense).</strong> However , the crucial property can be developed rigorously as the limit of a sequence of functions. The common seen examples are as follows :</p>
<table>
<thead>
<tr>
<th align="center">Examples</th>
<th align="center">Properties</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$$\begin{equation}\delta_n(x)&#x3D;\left{\begin{array}{lr}0,,,(-\infty,-\frac{1}{2n})\cup(\frac{1}{2n},\infty)\n,,,(-\frac{1}{2n},\frac{1}{2n})\end{array}\right.\end{equation}$$</td>
<td align="center">easy to integrate</td>
</tr>
<tr>
<td align="center">$$\delta_n(x)&#x3D;\frac{n}{\sqrt{\pi}}e^{-n^2x^2}$$</td>
<td align="center">its derivatives leads to Hermite Polynomials</td>
</tr>
<tr>
<td align="center">$$\delta_n(x)&#x3D;\frac{n}{\pi}\frac{1}{1+n^2x^2}$$</td>
<td align="center">&#x2F;</td>
</tr>
<tr>
<td align="center">$$\delta_n(x)&#x3D;\frac{sin(nx)}{\pi x}&#x3D;\frac{1}{2\pi}\int_{-n}^ne^{-ixt}dt$$</td>
<td align="center">Fourier analysis or quantum mechanics</td>
</tr>
<tr>
<td align="center"></td>
<td align="center">Dirichlet Kernel : $$\frac{sin[(n+\frac{1}{2})x]}{2\pi sin(\frac{1}{2}x)}$$</td>
</tr>
</tbody></table>
<p>​	They are of different uses as above.</p>
<p>​	For most physical purposes , the forms describing delta functions are quite adequate. However, from a mathematical point of view , the limits $$\underset{n\to\infty}{lim}\delta_n(x)$$ do not exist. To avoid the difficulty , label $$\delta(x)$$ a distribution , and write :<br>$$<br>\int_{-\infty}^{\infty}\delta(x)f(x)dx&#x3D;\underset{n\to\infty}{lim}\int_{-\infty}^{\infty}\delta_n(x)f(x)dx<br>$$</p>
<h4 id="square-quad-Properties-quad-of-quad-delta-x"><a href="#square-quad-Properties-quad-of-quad-delta-x" class="headerlink" title="$$\square\quad Properties\quad of\quad \delta(x)$$"></a>$$\square\quad Properties\quad of\quad \delta(x)$$</h4><p>​	$$\bullet$$ $$\delta(-x)&#x3D;\delta(x)$$</p>
<p>​	$$\bullet$$ $$\delta(ax)&#x3D;\frac{1}{|a|}\delta(x)$$</p>
<p>​		Proof :<br>$$<br>\int_{-\infty}^{\infty}f(x)\delta(ax)dx&#x3D;\frac{1}{|a|}\int_{-\infty}^{\infty}f(\frac{y}{|a|})\delta(y)dy&#x3D;\frac{f(0)}{|a|}<br>$$<br>​	$$\bullet$$ $$\int_{-\infty}^{\infty}f(x)\delta(x-x_0)dx&#x3D;f(x_0)$$</p>
<p>​	$$\bullet$$ If the argument of $$\delta(x)$$ is a function $$g(x)$$ with simple zeros at points $$a_i$$ on the real axis (and therefore $$g’(a_i)\neq0$$) , then<br>$$<br>\delta(g(x))&#x3D;\sum_i\frac{\delta(x-a_i)}{|g’(a_i)|}<br>$$<br>​		Proof :<br>$$<br>\int_{-\infty}^{\infty}f(x)\delta(x)dx&#x3D;\sum_i\int_{a_i-\varepsilon}^{a_i+\varepsilon}f(x)\delta[(x-a_i)g’(a_i)]dx\<br>(\varepsilon\to0)<br>$$<br>​	$$\bullet$$ Derivative of delta function :<br>$$<br>\int_{-\infty}^{\infty}f(x)\delta’(x-x_0)dx&#x3D;-\int_{-\infty}^{\infty}f’(x)\delta(x-x_0)dx&#x3D;-f’(x_0)<br>$$<br>​	This is the definition of $$\delta’(x-x_0)$$.</p>
<p>​	$$\bullet$$ In three dimensions , the delta function $$\delta(\vec{r})$$ is intepreted as $$\delta(x)\delta(y)\delta(z)$$ , irrespective of the coordinate system in use. Thus , in spherical polar coordinates ,<br>$$<br>\iiint f(\vec{r_2})\delta(\vec{r_2}-\vec{r_1})r_2^2dr_2\cdot sin\theta_2d\theta_2\cdot d\varphi&#x3D;f(\vec{r_1})<br>$$<br>​	$$\bullet$$ $$\delta(t-x)&#x3D;\frac{1}{2\pi}\int_{-\infty}^{\infty}e^{i\omega(t-x)}d\omega$$       (See Chapter20. , Fourier Integrals)</p>
<p>​	$$\bullet$$ Expansions of $$\delta(x)$$ are addressed in Chapter5. (Example5.1.7).</p>
<h4 id="square-quad-Kronecker-quad-Delta"><a href="#square-quad-Kronecker-quad-Delta" class="headerlink" title="$$\square\quad Kronecker\quad Delta$$"></a>$$\square\quad Kronecker\quad Delta$$</h4><p>​	The discrete analog of the Dirac delta function ,<br>$$<br>\begin{equation}<br>\delta_{ij}&#x3D;\left{<br>\begin{array}{lr}<br>1,,,i&#x3D;j\<br>0,,,i\neq j<br>\end{array}<br>\right.<br>\end{equation}<br>$$<br>​	Usage examples :<br>$$<br>\sum_{i,j}f_{ij}\delta_{ij}&#x3D;\sum_if_{ii}\<br>or\quad c_n&#x3D;\frac{1}{1+\delta_{n0}}\frac{2\pi}{L}<br>$$</p>
<h2 id="mathscr-Chapter2-quad-Determinants-quad-quad-Matrices"><a href="#mathscr-Chapter2-quad-Determinants-quad-quad-Matrices" class="headerlink" title="$$\mathscr{Chapter2\quad Determinants\quad &amp;\quad Matrices}$$"></a>$$\mathscr{Chapter2\quad Determinants\quad &amp;\quad Matrices}$$</h2><h3 id="S2-1-quad-Diterminants"><a href="#S2-1-quad-Diterminants" class="headerlink" title="$$\S2.1\quad Diterminants$$"></a>$$\S2.1\quad Diterminants$$</h3><p>​	We begin the study of matrices by solving linear equations that will lead us to determinants and matrices. The concept of determinant and the notation were introduced by the renowned German mathematician and philosopher $$Gottfried,,,Wilhelm,,,von,,,Leibniz$$.</p>
<h4 id="square-quad-Homogeneous-quad-Linear-quad-Equations"><a href="#square-quad-Homogeneous-quad-Linear-quad-Equations" class="headerlink" title="$$\square\quad Homogeneous\quad Linear\quad Equations$$"></a>$$\square\quad Homogeneous\quad Linear\quad Equations$$</h4><p>​	Suppose three unknowns $$x_1,x_2,x_3$$ (or $$n$$ equations with $$n$$ unknowns) :<br>$$<br>\begin{equation}<br>\left{<br>\begin{array}{lr}<br>a_1x_1+a_2x_2+a_3x_3&#x3D;0\<br>b_1x_1+b_2x_2+b_3x_3&#x3D;0\<br>c_1x_1+c_2x_2+c_3x_3&#x3D;0<br>\end{array}<br>\right.<br>\end{equation}<br>$$<br>​	The problem is to determine under what conditions there is any solution , apart from the trivial one $$x_1&#x3D;x_2&#x3D;x_3&#x3D;0$$. Using vectors , we have $$\vec{a}\cdot\vec{x}&#x3D;0,,,\vec{b}\cdot\vec{y}&#x3D;0,,,\vec{c}\cdot\vec{z}&#x3D;0$$. These three vector equations have the geometrical intepretation that $$x$$ is orthogonal to $$\vec{a},,,\vec{b},,,\vec{c}$$.</p>
<p>​	If the volume spanned by $$\vec{a},,,\vec{b},,,\vec{c}$$ given by determinant (or triple scalar product)<br>$$<br>D_3&#x3D;(\vec{a}\cross\vec{b})\cdot\vec{c}&#x3D;det(\vec{a},,,\vec{b},,,\vec{c})&#x3D;<br>\left\vert<br>\begin{matrix}<br>a_1&amp;a_2&amp;a_3\<br>b_1&amp;b_2&amp;b_3\<br>c_1&amp;c_2&amp;c_3<br>\end{matrix}<br>\right\vert<br>$$<br>​	is not zero , then there is the only trivial solution $$\vec{x}&#x3D;0$$.</p>
<p>​	Conversely , if the aforementional determinant of the coefficient vanishes , then one of the row vectors is a combination of the other two. $$\vec{c}\subseteq plane(\vec{a}\cross\vec{b})$$ , only ratios of $$x_i$$ are relevant.<br>$$<br>\frac{x_1}{x_3}&#x3D;\frac{a_2b_3-a_3b_2}{a_1b_2-a_2b_1}\qquad\frac{x_2}{x_3}&#x3D;-\frac{a_1b_3-a_3b_1}{a_1b_2-a_2b_1}<br>$$<br>​	This is <strong>Cramer’s Rule</strong> for homogeneous linear equation.</p>
<h4 id="square-quad-Inhomogeneous-quad-Linear-quad-Equation"><a href="#square-quad-Inhomogeneous-quad-Linear-quad-Equation" class="headerlink" title="$$\square\quad Inhomogeneous\quad Linear\quad Equation$$"></a>$$\square\quad Inhomogeneous\quad Linear\quad Equation$$</h4><p>​	Simple example :<br>$$<br>\begin{equation}<br>\left{<br>\begin{array}{lr}<br>a_1x_1+a_2x_2&#x3D;a_3\<br>b_1x_1+b_2x_2&#x3D;b_3<br>\end{array}<br>\right.<br>\end{equation}<br>$$</p>
<p>$$<br>\Longrightarrow<br>x_1&#x3D;\frac{\left\vert\begin{matrix}a_3&amp;a_2\b_3&amp;b_2\end{matrix}\right\vert}{\left\vert\begin{matrix}a_1&amp;a_2\b_1&amp;b_2\end{matrix}\right\vert}\qquad<br>x_2&#x3D;\frac{\left\vert\begin{matrix}a_3&amp;a_1\b_3&amp;b_1\end{matrix}\right\vert}{\left\vert\begin{matrix}a_1&amp;a_2\b_1&amp;b_2\end{matrix}\right\vert}<br>$$</p>
<p>​	This is <strong>Cramer’s Rule</strong> for inhomogeneous linear equation.</p>
<h4 id="square-quad-Definitions"><a href="#square-quad-Definitions" class="headerlink" title="$$\square\quad Definitions$$"></a>$$\square\quad Definitions$$</h4><p>​	Before defining a determinant , we need to introduce some related concepts and definitions.</p>
<p>​	$$\bullet$$ When we write two-dimensional ($$2-D$$) arrays of items , we identify the item in the $$n$$th horizontal row and the $$m$$th vertical column by the index set $$n,m$$ ; note that the row index is conventionally written first.</p>
<p>​	$$\bullet$$ Starting from a set of $$n$$ objects in some reference order (e.g. , the number sequence $$1,2,3,\cdots,n$$) , we can make a permutation of them to some other order ; the total number of distinct permutations that are possible is $$n!$$ (choose the first object $$n$$ ways , then choose the second in $$n-1$$ ways , etc.).</p>
<p>​	$$\bullet$$ Every permutation of $$n$$ objects can be reached from the reference order by a succession of pairwise interchanges (e.g. , $$1234\to4132$$ can be reached by the successive steps $$1234\to1432\to4132$$). Although the number of pairwise interchanges needed for a given permutation depends on the path (compare the above example with $$1234\to1243\to1423\to4123\to4132$$) , for a given permutation the number of interchanges will always either be <strong>even</strong> or <strong>odd</strong>. Thus a permutation can be identified as having either even or odd parity.</p>
<p>​	$$\bullet$$ It is convenient to introduce the <strong>Levi-Civita symbol</strong> , which for an $$n$$-object system is denoted by $$\varepsilon_{ij…}$$ , where $$\varepsilon$$ has $$n$$ subscripts , each of which identifies one of the objects.<br>$$<br>\begin{flalign}<br>\varepsilon_{ij…}&#x3D;&amp;,+1,,,ij…,an,,,even,,,permutation,,\<br>&#x3D;&amp;,-1,,,ij…,an,,,odd,,,permutation,,\<br>&#x3D;&amp;,0,,,ij…,not,,,a,,,permutation.<br>\end{flalign}<br>$$<br>​	We now define a determinant of order $$n$$ to be an $$n\cross n$$ square array of numbers (or functions) , with the array conventionally written within vertical bars (not parentheses , braces , or any other type of brackets) , as follows :<br>$$<br>D_n&#x3D;<br>\left\vert\begin{matrix}<br>a_{11}&amp;a_{12}&amp;\cdots&amp;a_{1n}\<br>a_{21}&amp;a_{22}&amp;\cdots&amp;a_{2n}\<br>a_{31}&amp;a_{32}&amp;\cdots&amp;a_{3n}\<br>\cdots&amp;\cdots&amp;\cdots&amp;\cdots\<br>a_{n1}&amp;a_{n2}&amp;\cdots&amp;a_{nn}<br>\end{matrix}\right\vert.<br>$$<br>​	The determinant $$D_n$$ has a value $$D_n&#x3D;\underset{ij…}{\sum}\varepsilon_{ij…}a_{1i}a_{2j}\cdots$$ .</p>
<h4 id="square-quad-Properties-quad-of-quad-Determinants"><a href="#square-quad-Properties-quad-of-quad-Determinants" class="headerlink" title="$$\square\quad Properties\quad of\quad Determinants$$"></a>$$\square\quad Properties\quad of\quad Determinants$$</h4><p>​	Take determinants of order $$3$$ for example.<br>$$<br>\left\vert\begin{matrix}a_{11}&amp;a_{12}&amp;a_{13}\a_{21}&amp;a_{22}&amp;a_{23}\a_{31}&amp;a_{32}&amp;a_{33}\end{matrix}\right\vert&#x3D;-\left\vert\begin{matrix}a_{12}&amp;a_{11}&amp;a_{13}\a_{22}&amp;a_{21}&amp;a_{23}\a_{32}&amp;a_{31}&amp;a_{33}\end{matrix}\right\vert&#x3D;\left\vert\begin{matrix}a_{11}&amp;a_{21}&amp;a_{31}\a_{12}&amp;a_{22}&amp;a_{32}\a_{13}&amp;a_{23}&amp;a_{33}\end{matrix}\right\vert\\<br>k\left\vert\begin{matrix}a_{11}&amp;a_{12}&amp;a_{13}\a_{21}&amp;a_{22}&amp;a_{23}\a_{31}&amp;a_{32}&amp;a_{33}\end{matrix}\right\vert&#x3D;\left\vert\begin{matrix}ka_{11}&amp;a_{12}&amp;a_{13}\ka_{21}&amp;a_{22}&amp;a_{23}\ka_{31}&amp;a_{32}&amp;a_{33}\end{matrix}\right\vert&#x3D;\left\vert\begin{matrix}ka_{11}&amp;ka_{12}&amp;ka_{13}\a_{21}&amp;a_{22}&amp;a_{23}\a_{31}&amp;a_{32}&amp;a_{33}\end{matrix}\right\vert\\<br>\left\vert\begin{matrix}a_{11}+b_1&amp;a_{12}&amp;a_{13}\a_{21}+b_2&amp;a_{22}&amp;a_{23}\a_{31}+b_3&amp;a_{32}&amp;a_{33}\end{matrix}\right\vert&#x3D;\left\vert\begin{matrix}a_{11}&amp;a_{12}&amp;a_{13}\a_{21}&amp;a_{22}&amp;a_{23}\a_{31}&amp;a_{32}&amp;a_{33}\end{matrix}\right\vert+\left\vert\begin{matrix}b_1&amp;a_{12}&amp;a_{13}\b_2&amp;a_{22}&amp;a_{23}\b_3&amp;a_{32}&amp;a_{33}\end{matrix}\right\vert<br>$$<br>​	$$\bullet$$ Any determinant with two rows equal , or two columns equal , has the value zero. To prove this , interchange the two identical rows or columns ; the determinant both remains the same and changes sign , and therefore must have the value zero.</p>
<p>​	$$\bullet$$ An extension of the above is that if two rows (or columns) are proportional , the determinant is zero.</p>
<p>​	$$\bullet$$ The value of a determinant  is unchanged if a multiple of one row is added (column by column) to another row or  if a multiple of one column is added (row by row) to another column.</p>
<p>​	$$\bullet$$ If each element in a row or each element in a column is zero ,  the determinant has the value zero.</p>
<h4 id="square-quad-Laplacian-quad-Development-quad-by-quad-Minor"><a href="#square-quad-Laplacian-quad-Development-quad-by-quad-Minor" class="headerlink" title="$$\square\quad Laplacian\quad Development\quad by\quad Minor$$"></a>$$\square\quad Laplacian\quad Development\quad by\quad Minor$$</h4><p>​	 The fact that a determinant of order $$n$$ expands into $$n!$$ terms  means that it is important to identify efficient means for determinant evaluation. One approach is to expand in terms of  minors. The minor corresponding to $$a_{ij}$$ , denoted $$M_{ij}$$ , or $$M_{ij}(a)$$ if we need to identify $$M$$ as coming from the $$a_{ij}$$ , is the determinant (of order $$n-1$$) produced by stiking out row $$i$$ and column $$j$$ of the original determinant. And we get<br>$$<br>D_n&#x3D;\sum_{j&#x3D;1}^{n}a_{ij}(-1)^{i+j}M_{ij}<br>$$</p>
<h4 id="square-quad-Linear-quad-Equation-quad-Systems"><a href="#square-quad-Linear-quad-Equation-quad-Systems" class="headerlink" title="$$\square\quad Linear\quad Equation\quad Systems$$"></a>$$\square\quad Linear\quad Equation\quad Systems$$</h4><p>​	For equation<br>$$<br>\begin{equation}<br>\left{<br>\begin{array}{lr}<br>a_1x_1+a_2x_2+a_3x_3&#x3D;h_1\<br>b_1x_1+b_2x_2+b_3x_3&#x3D;h_2\<br>c_1x_1+c_2x_2+c_3x_3&#x3D;h_3<br>\end{array}<br>\right.<br>\end{equation}<br>$$<br>​	We define<br>$$<br>D&#x3D;\left\vert\begin{matrix}a_1&amp;a_2&amp;a_3\b_1&amp;b_2&amp;b_3\c_1&amp;c_2&amp;c_3\end{matrix}\right\vert.<br>$$<br>​	Then we have<br>$$<br>\begin{flalign}x_1D&#x3D;&amp;,\left\vert\begin{matrix}a_1x_1&amp;a_2&amp;a_3\b_1x_1&amp;b_2&amp;b_3\c_1x_1&amp;c_2&amp;c_3\end{matrix}\right\vert\\&#x3D;&amp;,\left\vert\begin{matrix}a_1x_1+a_2x_2+a_3x_3&amp;a_2&amp;a_3\b_1x_1+b_2x_2+b_3x_3&amp;b_2&amp;b_3\c_1x_1+c_2x_2+c_3x_3&amp;c_2&amp;c_3\end{matrix}\right\vert\\&#x3D;&amp;,\left\vert\begin{matrix}h_1&amp;a_2&amp;a_3\h_2&amp;b_2&amp;b_3\h_3&amp;c_2&amp;c_3\end{matrix}\right\vert\\\Longrightarrow\quad x_1&#x3D;\frac{1}{D}\left\vert\begin{matrix}h_1&amp;a_2&amp;a_3\h_2&amp;b_2&amp;b_3\h_3&amp;c_2&amp;c_3\end{matrix}\right\vert,,&amp;,x_2&#x3D;\frac{1}{D}\left\vert\begin{matrix}a_1&amp;h_1&amp;a_3\b_1&amp;h_2&amp;b_3\c_1&amp;h_3&amp;c_3\end{matrix}\right\vert,,x_3&#x3D;\frac{1}{D}\left\vert\begin{matrix}a_1&amp;a_2&amp;h_1\b_1&amp;b_2&amp;h_2\c_1&amp;c_2&amp;h_3\end{matrix}\right\vert\end{flalign}<br>$$<br>​	This is the <strong>Cramer’s Rule</strong>.</p>
<p>​	If $$D$$ is nonzero , the above construction of the $$x_i$$ is definitive and unique , so that there will be exactly one solution to the equation set.</p>
<h4 id="square-quad-Determinants-quad-quad-Linear-quad-Dependence"><a href="#square-quad-Determinants-quad-quad-Linear-quad-Dependence" class="headerlink" title="$$\square\quad Determinants\quad &amp;\quad Linear\quad Dependence$$"></a>$$\square\quad Determinants\quad &amp;\quad Linear\quad Dependence$$</h4><p>​	 If the coefficients of $$n$$ linear forms in $$n$$ variables form a nonzero determinant , the forms  are linearly independent ; if the determinant of the coefficients is zero , the forms exhibit  linear dependence.</p>
<h4 id="square-quad-Linearly-quad-Dependent-quad-Equations"><a href="#square-quad-Linearly-quad-Dependent-quad-Equations" class="headerlink" title="$$\square\quad Linearly\quad Dependent\quad Equations$$"></a>$$\square\quad Linearly\quad Dependent\quad Equations$$</h4><h5 id="Situation-1"><a href="#Situation-1" class="headerlink" title="Situation $$1$$"></a>Situation $$1$$</h5><p>​	All the equations are homogeneous (which means all the right hand side quantities $$ h_i$$ are zero). Then , one or more of the equations in the set will be equivalent  to linear combinations of others , and  we will have less than $$n$$ equations in our $$n$$ variables. We can then assign one (or in some  cases , more than one) variable an arbitrary value , obtaining the others as functions of the  assigned variables. We thus have a <strong>manifold</strong> (i.e. , a parameterized set) of solutions to our equation system.</p>
<h5 id="Situation-2"><a href="#Situation-2" class="headerlink" title="Situation $$2$$"></a>Situation $$2$$</h5><p>​	A second case is where we have (or combine equations so that we have) the same linear  form in two equations , but with different values of the right-hand quantities $$h_i$$. In that case the  equations are mutually inconsistent , and the equation system has no solution.</p>
<h5 id="Situation-3"><a href="#Situation-3" class="headerlink" title="Situation $$3$$"></a>Situation $$3$$</h5><p>​	A third , related case , is where we have a duplicated linear form , but with a common  value of $$h_i$$. This also leads to a solution manifold.</p>
<h4 id="square-quad-Numerical-quad-Evaluation"><a href="#square-quad-Numerical-quad-Evaluation" class="headerlink" title="$$\square\quad Numerical\quad Evaluation$$"></a>$$\square\quad Numerical\quad Evaluation$$</h4><p>​	There are many methods to evaluate determinants , even using computers. We use the <strong>Gauss Elimination</strong> to calculate determinants , which is a versatile procedure that can be used for evaluating determinants, for solving linear equation systems, and (as we will see later) even for matrix inversion.</p>
<p>​	Gauss Elimination : make the determinant into a form that all the entries in the lower triangle of the determinant. Then the only effective part is the product of thediagonal elements.</p>
<h3 id="S2-2-quad-Matrices"><a href="#S2-2-quad-Matrices" class="headerlink" title="$$\S2.2\quad Matrices$$"></a>$$\S2.2\quad Matrices$$</h3><p>​	Matrices are $$2-D$$ arrays of numbers or functions that obey the laws that define <strong>matrix algebra</strong>.</p>
<h4 id="square-quad-Basic-quad-Definitions"><a href="#square-quad-Basic-quad-Definitions" class="headerlink" title="$$\square\quad Basic\quad Definitions$$"></a>$$\square\quad Basic\quad Definitions$$</h4><p>​	A matrix is a set of numbers or functions in a $$2-D$$ square or rectangular array. A matrix with $$m$$ (horizontal) rows and $$n$$ (vertical) columns is known as an $$m\cross n$$ matrix. When we introduced determinants , when row and column indices or dimensions are mentioned together , it is customary to write the row indicaters first.</p>
<p>​	A matrix for which $$n&#x3D;m$$ is termed <strong>square</strong>; One consisting of a single column (an $$m\cross1$$ matrix) is often called a <strong>column vector</strong> , while a matrix with only one row (therefore $$1\cross n$$) is a <strong>row vector</strong>.</p>
<h4 id="square-quad-Equality"><a href="#square-quad-Equality" class="headerlink" title="$$\square\quad Equality$$"></a>$$\square\quad Equality$$</h4><p>​	If $$A$$ and $$B$$ are matrices , $$A&#x3D;B$$ only if $$a_{ij}&#x3D;b_{ij}$$ for all values of $$i$$ and $$j$$. A necessary but not sufficient condition for equality is that both matrices have the same dimensions.</p>
<h4 id="square-quad-Addition-quad-Subtraction"><a href="#square-quad-Addition-quad-Subtraction" class="headerlink" title="$$\square\quad Addition,,,\quad Subtraction$$"></a>$$\square\quad Addition,,,\quad Subtraction$$</h4><p>​	Addition and subtraction are defined only for matrices $$A$$ and $$B$$ of the same dimensions , in which case $$A\pm B&#x3D;C$$ , with $$c_{ij}&#x3D;a_{ij}\pm b_{ij}$$ for all values of $$i$$ and $$j$$. Addition is <strong>commutative</strong> ($$A+B&#x3D;B+A$$) and also <strong>associative</strong> ($$(A+B)+C&#x3D;A+(B+C)$$). A matrix with all elements zero , called a <strong>null matrix</strong> or <strong>zero matrix</strong> , can either be written as $$O$$ or as a simple zero. Thus for all $$A$$ ,<br>$$<br>A+0&#x3D;0+A&#x3D;A<br>$$</p>
<h4 id="square-quad-Multiplication-quad-by-quad-a-quad-Scalar"><a href="#square-quad-Multiplication-quad-by-quad-a-quad-Scalar" class="headerlink" title="$$\square\quad Multiplication\quad (by\quad a\quad Scalar)$$"></a>$$\square\quad Multiplication\quad (by\quad a\quad Scalar)$$</h4><p>​	Here we have $B&#x3D;\alpha A$ , with $b_{ij}&#x3D;\alpha a_{ij}$ for all values of $i$ and $j$. This operation is commutative , with $\alpha A&#x3D;A\alpha$.</p>
<p>​	Note that the definition of multiplication by a scalar causes <strong>each</strong> element of marix $A$ to be multiplied by the scalar factor , so there is<br>$$<br>det(\alpha A)&#x3D;\alpha^ndet(A)<br>$$</p>
<h4 id="square-quad-Matrix-quad-Multiplication-quad-Inner-quad-Product"><a href="#square-quad-Matrix-quad-Multiplication-quad-Inner-quad-Product" class="headerlink" title="$$\square\quad Matrix\quad Multiplication\quad (Inner\quad Product)$$"></a>$$\square\quad Matrix\quad Multiplication\quad (Inner\quad Product)$$</h4><p>​	<strong>Matrix multiplication</strong> is not an element-by-element operation like addition or multiplication by a scalar. The <strong>inner product</strong> of matrices $A$ and $B$ is defined as<br>$$<br>AB&#x3D;C,,,\quad with\quad c_{ij}&#x3D;\sum_ka_{ik}b_{kj}<br>$$<br>​	This definition causes the $ij$ element of $C$ to be formed from the entire $i$th row of $A$ and the entire $j$th column of $B$. And as you can realize , $AB\neq BA$.</p>
<p>​	It is useful to define the <strong>commutator</strong> of $A$ and $B$ ,<br>$$<br>[A,B]&#x3D;AB-BA<br>$$<br>​	which , as stated above , will in many cases be nonzero.</p>
<p>​	But , matrix multiplication is <strong>associative</strong> , meaning that $A(BC)&#x3D;(AB)C$.</p>
<h4 id="square-quad-Unit-quad-Matrix"><a href="#square-quad-Unit-quad-Matrix" class="headerlink" title="$\square\quad Unit\quad Matrix$"></a>$\square\quad Unit\quad Matrix$</h4><p>​	By direct matrix multiplication , it is possible to show that a square matrix with elements of value unity on its <strong>principal diagonal</strong> (the elements $(i,j)$ with $i&#x3D;j$) , and zeros everywhere else , will leave unchanged any matrix with which it can be multiplied. For example , the $3\cross3$ unit matrix has the form<br>$$<br>\left\lgroup<br>\begin{array}{lr}<br>1&amp;0&amp;0\<br>0&amp;1&amp;0\<br>0&amp;0&amp;1<br>\end{array}<br>\right\rgroup<br>$$</p>
<h2 id="mathscr-Appendix1-quad-Words"><a href="#mathscr-Appendix1-quad-Words" class="headerlink" title="$$\mathscr{Appendix1\quad Words}$$"></a>$$\mathscr{Appendix1\quad Words}$$</h2><p>preliminary n. (pl. preliminaries) 初步</p>
<p>crucial adj. 至关重要的，极好的</p>
<p>monotonic adj. 单调的</p>
<p>termwise adv.&#x2F;adj. 逐项地&#x2F;的</p>
<p>induction n. 归纳法</p>
<p>duplicated adj. 重复的</p>
</div>

  

</article>


  



  



  



  



  



  






              </div>
            </div>
          </div>
        </div>
      </div>
    

    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
